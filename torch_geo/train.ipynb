{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Downloaded libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "# Local files\n",
    "from dataset_graphs import NNDataset\n",
    "from models import Trainer_GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAINING_SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epoch = 100\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded, 800 training samples and 200 testing samples\n"
     ]
    }
   ],
   "source": [
    "nndataset = NNDataset(root=\"../\")\n",
    "\n",
    "size = len(nndataset)\n",
    "train_num = int(size * TRAINING_SPLIT)\n",
    "test_num = size - train_num\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=nndataset[:train_num], batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(\n",
    "    dataset=nndataset[train_num:], batch_size=test_num, shuffle=True)\n",
    "\n",
    "print(\n",
    "    f\"Dataset loaded, {train_num} training samples and {test_num} testing samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(design=[16], edge_index=[2, 34144], x=[1319, 504], y_edge=[17072, 1], y_node=[1319, 1], input_mask=[1319, 1], num_nodes=1319, batch=[1319], ptr=[17])\n"
     ]
    }
   ],
   "source": [
    "data = iter(train_loader).next()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Trainer_GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 100:\n",
      "Training Loss: 0.903748  [    0/  800]\n",
      "Training Loss: 0.347704  [  160/  800]\n",
      "Training Loss: 0.321701  [  320/  800]\n",
      "Training Loss: 0.260181  [  480/  800]\n",
      "Training Loss: 0.343222  [  640/  800]\n",
      "Epoch 2 / 100:\n",
      "Training Loss: 0.233592  [    0/  800]\n",
      "Training Loss: 0.399781  [  160/  800]\n",
      "Training Loss: 0.384323  [  320/  800]\n",
      "Training Loss: 0.339276  [  480/  800]\n",
      "Training Loss: 0.253339  [  640/  800]\n",
      "Epoch 3 / 100:\n",
      "Training Loss: 0.322542  [    0/  800]\n",
      "Training Loss: 0.231674  [  160/  800]\n",
      "Training Loss: 0.296107  [  320/  800]\n",
      "Training Loss: 0.268927  [  480/  800]\n",
      "Training Loss: 0.347784  [  640/  800]\n",
      "Epoch 4 / 100:\n",
      "Training Loss: 0.405687  [    0/  800]\n",
      "Training Loss: 0.344848  [  160/  800]\n",
      "Training Loss: 0.301651  [  320/  800]\n",
      "Training Loss: 0.299163  [  480/  800]\n",
      "Training Loss: 0.337260  [  640/  800]\n",
      "Epoch 5 / 100:\n",
      "Training Loss: 0.365052  [    0/  800]\n",
      "Training Loss: 0.278226  [  160/  800]\n",
      "Training Loss: 0.401495  [  320/  800]\n",
      "Training Loss: 0.356757  [  480/  800]\n",
      "Training Loss: 0.341595  [  640/  800]\n",
      "Epoch 6 / 100:\n",
      "Training Loss: 0.326343  [    0/  800]\n",
      "Training Loss: 0.374244  [  160/  800]\n",
      "Training Loss: 0.292648  [  320/  800]\n",
      "Training Loss: 0.316361  [  480/  800]\n",
      "Training Loss: 0.272903  [  640/  800]\n",
      "Epoch 7 / 100:\n",
      "Training Loss: 0.240344  [    0/  800]\n",
      "Training Loss: 0.227607  [  160/  800]\n",
      "Training Loss: 0.302113  [  320/  800]\n",
      "Training Loss: 0.369894  [  480/  800]\n",
      "Training Loss: 0.316394  [  640/  800]\n",
      "Epoch 8 / 100:\n",
      "Training Loss: 0.452447  [    0/  800]\n",
      "Training Loss: 0.421297  [  160/  800]\n",
      "Training Loss: 0.441721  [  320/  800]\n",
      "Training Loss: 0.493414  [  480/  800]\n",
      "Training Loss: 0.415969  [  640/  800]\n",
      "Epoch 9 / 100:\n",
      "Training Loss: 0.381916  [    0/  800]\n",
      "Training Loss: 0.284470  [  160/  800]\n",
      "Training Loss: 0.397806  [  320/  800]\n",
      "Training Loss: 0.333045  [  480/  800]\n",
      "Training Loss: 0.285221  [  640/  800]\n",
      "Epoch 10 / 100:\n",
      "Training Loss: 0.318036  [    0/  800]\n",
      "Training Loss: 0.353266  [  160/  800]\n",
      "Training Loss: 0.291046  [  320/  800]\n",
      "Training Loss: 0.331079  [  480/  800]\n",
      "Training Loss: 0.388118  [  640/  800]\n",
      "Epoch 11 / 100:\n",
      "Training Loss: 0.288426  [    0/  800]\n",
      "Training Loss: 0.209049  [  160/  800]\n",
      "Training Loss: 0.405144  [  320/  800]\n",
      "Training Loss: 0.352190  [  480/  800]\n",
      "Training Loss: 0.321687  [  640/  800]\n",
      "Epoch 12 / 100:\n",
      "Training Loss: 0.260712  [    0/  800]\n",
      "Training Loss: 0.285780  [  160/  800]\n",
      "Training Loss: 0.292881  [  320/  800]\n",
      "Training Loss: 0.335906  [  480/  800]\n",
      "Training Loss: 0.198507  [  640/  800]\n",
      "Epoch 13 / 100:\n",
      "Training Loss: 0.264217  [    0/  800]\n",
      "Training Loss: 0.294658  [  160/  800]\n",
      "Training Loss: 0.322159  [  320/  800]\n",
      "Training Loss: 0.421147  [  480/  800]\n",
      "Training Loss: 0.403378  [  640/  800]\n",
      "Epoch 14 / 100:\n",
      "Training Loss: 0.239704  [    0/  800]\n",
      "Training Loss: 0.264894  [  160/  800]\n",
      "Training Loss: 0.317304  [  320/  800]\n",
      "Training Loss: 0.349201  [  480/  800]\n",
      "Training Loss: 0.437830  [  640/  800]\n",
      "Epoch 15 / 100:\n",
      "Training Loss: 0.337350  [    0/  800]\n",
      "Training Loss: 0.267843  [  160/  800]\n",
      "Training Loss: 0.356731  [  320/  800]\n",
      "Training Loss: 0.365723  [  480/  800]\n",
      "Training Loss: 0.334650  [  640/  800]\n",
      "Epoch 16 / 100:\n",
      "Training Loss: 0.320524  [    0/  800]\n",
      "Training Loss: 0.402923  [  160/  800]\n",
      "Training Loss: 0.453918  [  320/  800]\n",
      "Training Loss: 0.324464  [  480/  800]\n",
      "Training Loss: 0.314705  [  640/  800]\n",
      "Epoch 17 / 100:\n",
      "Training Loss: 0.319380  [    0/  800]\n",
      "Training Loss: 0.319631  [  160/  800]\n",
      "Training Loss: 0.277162  [  320/  800]\n",
      "Training Loss: 0.278625  [  480/  800]\n",
      "Training Loss: 0.295977  [  640/  800]\n",
      "Epoch 18 / 100:\n",
      "Training Loss: 0.320872  [    0/  800]\n",
      "Training Loss: 0.283686  [  160/  800]\n",
      "Training Loss: 0.378601  [  320/  800]\n",
      "Training Loss: 0.245006  [  480/  800]\n",
      "Training Loss: 0.257659  [  640/  800]\n",
      "Epoch 19 / 100:\n",
      "Training Loss: 0.311266  [    0/  800]\n",
      "Training Loss: 0.305638  [  160/  800]\n",
      "Training Loss: 0.329478  [  320/  800]\n",
      "Training Loss: 0.327156  [  480/  800]\n",
      "Training Loss: 0.355136  [  640/  800]\n",
      "Epoch 20 / 100:\n",
      "Training Loss: 0.334880  [    0/  800]\n",
      "Training Loss: 0.310340  [  160/  800]\n",
      "Training Loss: 0.365664  [  320/  800]\n",
      "Training Loss: 0.246956  [  480/  800]\n",
      "Training Loss: 0.286962  [  640/  800]\n",
      "Epoch 21 / 100:\n",
      "Training Loss: 0.311110  [    0/  800]\n",
      "Training Loss: 0.349732  [  160/  800]\n",
      "Training Loss: 0.309327  [  320/  800]\n",
      "Training Loss: 0.352053  [  480/  800]\n",
      "Training Loss: 0.297100  [  640/  800]\n",
      "Epoch 22 / 100:\n",
      "Training Loss: 0.300708  [    0/  800]\n",
      "Training Loss: 0.345934  [  160/  800]\n",
      "Training Loss: 0.422373  [  320/  800]\n",
      "Training Loss: 0.294424  [  480/  800]\n",
      "Training Loss: 0.332464  [  640/  800]\n",
      "Epoch 23 / 100:\n",
      "Training Loss: 0.445292  [    0/  800]\n",
      "Training Loss: 0.287979  [  160/  800]\n",
      "Training Loss: 0.301011  [  320/  800]\n",
      "Training Loss: 0.247243  [  480/  800]\n",
      "Training Loss: 0.218273  [  640/  800]\n",
      "Epoch 24 / 100:\n",
      "Training Loss: 0.236475  [    0/  800]\n",
      "Training Loss: 0.324149  [  160/  800]\n",
      "Training Loss: 0.299695  [  320/  800]\n",
      "Training Loss: 0.353327  [  480/  800]\n",
      "Training Loss: 0.305491  [  640/  800]\n",
      "Epoch 25 / 100:\n",
      "Training Loss: 0.320448  [    0/  800]\n",
      "Training Loss: 0.261447  [  160/  800]\n",
      "Training Loss: 0.289853  [  320/  800]\n",
      "Training Loss: 0.226454  [  480/  800]\n",
      "Training Loss: 0.300298  [  640/  800]\n",
      "Epoch 26 / 100:\n",
      "Training Loss: 0.358476  [    0/  800]\n",
      "Training Loss: 0.190091  [  160/  800]\n",
      "Training Loss: 0.352387  [  320/  800]\n",
      "Training Loss: 0.266063  [  480/  800]\n",
      "Training Loss: 0.332021  [  640/  800]\n",
      "Epoch 27 / 100:\n",
      "Training Loss: 0.279086  [    0/  800]\n",
      "Training Loss: 0.280789  [  160/  800]\n",
      "Training Loss: 0.330854  [  320/  800]\n",
      "Training Loss: 0.298289  [  480/  800]\n",
      "Training Loss: 0.276864  [  640/  800]\n",
      "Epoch 28 / 100:\n",
      "Training Loss: 0.265981  [    0/  800]\n",
      "Training Loss: 0.176720  [  160/  800]\n",
      "Training Loss: 0.277932  [  320/  800]\n",
      "Training Loss: 0.275934  [  480/  800]\n",
      "Training Loss: 0.426341  [  640/  800]\n",
      "Epoch 29 / 100:\n",
      "Training Loss: 0.232584  [    0/  800]\n",
      "Training Loss: 0.379919  [  160/  800]\n",
      "Training Loss: 0.319796  [  320/  800]\n",
      "Training Loss: 0.302803  [  480/  800]\n",
      "Training Loss: 0.260530  [  640/  800]\n",
      "Epoch 30 / 100:\n",
      "Training Loss: 0.379193  [    0/  800]\n",
      "Training Loss: 0.317735  [  160/  800]\n",
      "Training Loss: 0.375988  [  320/  800]\n",
      "Training Loss: 0.299584  [  480/  800]\n",
      "Training Loss: 0.310777  [  640/  800]\n",
      "Epoch 31 / 100:\n",
      "Training Loss: 0.427278  [    0/  800]\n",
      "Training Loss: 0.362138  [  160/  800]\n",
      "Training Loss: 0.467485  [  320/  800]\n",
      "Training Loss: 0.252877  [  480/  800]\n",
      "Training Loss: 0.325143  [  640/  800]\n",
      "Epoch 32 / 100:\n",
      "Training Loss: 0.350350  [    0/  800]\n",
      "Training Loss: 0.435295  [  160/  800]\n",
      "Training Loss: 0.377007  [  320/  800]\n",
      "Training Loss: 0.270498  [  480/  800]\n",
      "Training Loss: 0.453533  [  640/  800]\n",
      "Epoch 33 / 100:\n",
      "Training Loss: 0.369841  [    0/  800]\n",
      "Training Loss: 0.294041  [  160/  800]\n",
      "Training Loss: 0.296409  [  320/  800]\n",
      "Training Loss: 0.333836  [  480/  800]\n",
      "Training Loss: 0.262962  [  640/  800]\n",
      "Epoch 34 / 100:\n",
      "Training Loss: 0.272466  [    0/  800]\n",
      "Training Loss: 0.282624  [  160/  800]\n",
      "Training Loss: 0.429300  [  320/  800]\n",
      "Training Loss: 0.281916  [  480/  800]\n",
      "Training Loss: 0.294469  [  640/  800]\n",
      "Epoch 35 / 100:\n",
      "Training Loss: 0.382723  [    0/  800]\n",
      "Training Loss: 0.309735  [  160/  800]\n",
      "Training Loss: 0.327635  [  320/  800]\n",
      "Training Loss: 0.439502  [  480/  800]\n",
      "Training Loss: 0.256486  [  640/  800]\n",
      "Epoch 36 / 100:\n",
      "Training Loss: 0.366921  [    0/  800]\n",
      "Training Loss: 0.305756  [  160/  800]\n",
      "Training Loss: 0.421822  [  320/  800]\n",
      "Training Loss: 0.369351  [  480/  800]\n",
      "Training Loss: 0.264146  [  640/  800]\n",
      "Epoch 37 / 100:\n",
      "Training Loss: 0.387223  [    0/  800]\n",
      "Training Loss: 0.302457  [  160/  800]\n",
      "Training Loss: 0.306922  [  320/  800]\n",
      "Training Loss: 0.435708  [  480/  800]\n",
      "Training Loss: 0.259445  [  640/  800]\n",
      "Epoch 38 / 100:\n",
      "Training Loss: 0.344953  [    0/  800]\n",
      "Training Loss: 0.357467  [  160/  800]\n",
      "Training Loss: 0.297705  [  320/  800]\n",
      "Training Loss: 0.347008  [  480/  800]\n",
      "Training Loss: 0.381928  [  640/  800]\n",
      "Epoch 39 / 100:\n",
      "Training Loss: 0.233847  [    0/  800]\n",
      "Training Loss: 0.398272  [  160/  800]\n",
      "Training Loss: 0.349382  [  320/  800]\n",
      "Training Loss: 0.265952  [  480/  800]\n",
      "Training Loss: 0.360614  [  640/  800]\n",
      "Epoch 40 / 100:\n",
      "Training Loss: 0.344416  [    0/  800]\n",
      "Training Loss: 0.371030  [  160/  800]\n",
      "Training Loss: 0.278534  [  320/  800]\n",
      "Training Loss: 0.282498  [  480/  800]\n",
      "Training Loss: 0.349838  [  640/  800]\n",
      "Epoch 41 / 100:\n",
      "Training Loss: 0.427702  [    0/  800]\n",
      "Training Loss: 0.316698  [  160/  800]\n",
      "Training Loss: 0.340158  [  320/  800]\n",
      "Training Loss: 0.360605  [  480/  800]\n",
      "Training Loss: 0.399077  [  640/  800]\n",
      "Epoch 42 / 100:\n",
      "Training Loss: 0.269807  [    0/  800]\n",
      "Training Loss: 0.273346  [  160/  800]\n",
      "Training Loss: 0.403787  [  320/  800]\n",
      "Training Loss: 0.250044  [  480/  800]\n",
      "Training Loss: 0.281185  [  640/  800]\n",
      "Epoch 43 / 100:\n",
      "Training Loss: 0.364512  [    0/  800]\n",
      "Training Loss: 0.276977  [  160/  800]\n",
      "Training Loss: 0.264621  [  320/  800]\n",
      "Training Loss: 0.410748  [  480/  800]\n",
      "Training Loss: 0.268773  [  640/  800]\n",
      "Epoch 44 / 100:\n",
      "Training Loss: 0.254030  [    0/  800]\n",
      "Training Loss: 0.261262  [  160/  800]\n",
      "Training Loss: 0.365197  [  320/  800]\n",
      "Training Loss: 0.352006  [  480/  800]\n",
      "Training Loss: 0.298293  [  640/  800]\n",
      "Epoch 45 / 100:\n",
      "Training Loss: 0.326857  [    0/  800]\n",
      "Training Loss: 0.215615  [  160/  800]\n",
      "Training Loss: 0.319524  [  320/  800]\n",
      "Training Loss: 0.363912  [  480/  800]\n",
      "Training Loss: 0.288066  [  640/  800]\n",
      "Epoch 46 / 100:\n",
      "Training Loss: 0.272128  [    0/  800]\n",
      "Training Loss: 0.252588  [  160/  800]\n",
      "Training Loss: 0.338243  [  320/  800]\n",
      "Training Loss: 0.262919  [  480/  800]\n",
      "Training Loss: 0.428566  [  640/  800]\n",
      "Epoch 47 / 100:\n",
      "Training Loss: 0.429629  [    0/  800]\n",
      "Training Loss: 0.338869  [  160/  800]\n",
      "Training Loss: 0.232144  [  320/  800]\n",
      "Training Loss: 0.303082  [  480/  800]\n",
      "Training Loss: 0.274859  [  640/  800]\n",
      "Epoch 48 / 100:\n",
      "Training Loss: 0.248175  [    0/  800]\n",
      "Training Loss: 0.263078  [  160/  800]\n",
      "Training Loss: 0.307086  [  320/  800]\n",
      "Training Loss: 0.455452  [  480/  800]\n",
      "Training Loss: 0.287386  [  640/  800]\n",
      "Epoch 49 / 100:\n",
      "Training Loss: 0.474962  [    0/  800]\n",
      "Training Loss: 0.253906  [  160/  800]\n",
      "Training Loss: 0.278203  [  320/  800]\n",
      "Training Loss: 0.295401  [  480/  800]\n",
      "Training Loss: 0.283136  [  640/  800]\n",
      "Epoch 50 / 100:\n",
      "Training Loss: 0.288805  [    0/  800]\n",
      "Training Loss: 0.316167  [  160/  800]\n",
      "Training Loss: 0.346963  [  320/  800]\n",
      "Training Loss: 0.414156  [  480/  800]\n",
      "Training Loss: 0.316744  [  640/  800]\n",
      "Epoch 51 / 100:\n",
      "Training Loss: 0.235461  [    0/  800]\n",
      "Training Loss: 0.294102  [  160/  800]\n",
      "Training Loss: 0.277737  [  320/  800]\n",
      "Training Loss: 0.391961  [  480/  800]\n",
      "Training Loss: 0.321673  [  640/  800]\n",
      "Epoch 52 / 100:\n",
      "Training Loss: 0.225375  [    0/  800]\n",
      "Training Loss: 0.286262  [  160/  800]\n",
      "Training Loss: 0.242598  [  320/  800]\n",
      "Training Loss: 0.285322  [  480/  800]\n",
      "Training Loss: 0.315046  [  640/  800]\n",
      "Epoch 53 / 100:\n",
      "Training Loss: 0.380316  [    0/  800]\n",
      "Training Loss: 0.327120  [  160/  800]\n",
      "Training Loss: 0.390300  [  320/  800]\n",
      "Training Loss: 0.281516  [  480/  800]\n",
      "Training Loss: 0.347576  [  640/  800]\n",
      "Epoch 54 / 100:\n",
      "Training Loss: 0.379796  [    0/  800]\n",
      "Training Loss: 0.333669  [  160/  800]\n",
      "Training Loss: 0.305161  [  320/  800]\n",
      "Training Loss: 0.337165  [  480/  800]\n",
      "Training Loss: 0.367460  [  640/  800]\n",
      "Epoch 55 / 100:\n",
      "Training Loss: 0.273514  [    0/  800]\n",
      "Training Loss: 0.356465  [  160/  800]\n",
      "Training Loss: 0.280914  [  320/  800]\n",
      "Training Loss: 0.275648  [  480/  800]\n",
      "Training Loss: 0.377242  [  640/  800]\n",
      "Epoch 56 / 100:\n",
      "Training Loss: 0.360792  [    0/  800]\n",
      "Training Loss: 0.351144  [  160/  800]\n",
      "Training Loss: 0.367913  [  320/  800]\n",
      "Training Loss: 0.321712  [  480/  800]\n",
      "Training Loss: 0.330465  [  640/  800]\n",
      "Epoch 57 / 100:\n",
      "Training Loss: 0.295603  [    0/  800]\n",
      "Training Loss: 0.332079  [  160/  800]\n",
      "Training Loss: 0.325386  [  320/  800]\n",
      "Training Loss: 0.291292  [  480/  800]\n",
      "Training Loss: 0.335676  [  640/  800]\n",
      "Epoch 58 / 100:\n",
      "Training Loss: 0.247281  [    0/  800]\n",
      "Training Loss: 0.456392  [  160/  800]\n",
      "Training Loss: 0.404645  [  320/  800]\n",
      "Training Loss: 0.296638  [  480/  800]\n",
      "Training Loss: 0.321643  [  640/  800]\n",
      "Epoch 59 / 100:\n",
      "Training Loss: 0.254885  [    0/  800]\n",
      "Training Loss: 0.187753  [  160/  800]\n",
      "Training Loss: 0.334245  [  320/  800]\n",
      "Training Loss: 0.328958  [  480/  800]\n",
      "Training Loss: 0.278995  [  640/  800]\n",
      "Epoch 60 / 100:\n",
      "Training Loss: 0.386083  [    0/  800]\n",
      "Training Loss: 0.281066  [  160/  800]\n",
      "Training Loss: 0.297034  [  320/  800]\n",
      "Training Loss: 0.296005  [  480/  800]\n",
      "Training Loss: 0.396861  [  640/  800]\n",
      "Epoch 61 / 100:\n",
      "Training Loss: 0.267247  [    0/  800]\n",
      "Training Loss: 0.255162  [  160/  800]\n",
      "Training Loss: 0.374651  [  320/  800]\n",
      "Training Loss: 0.332652  [  480/  800]\n",
      "Training Loss: 0.341807  [  640/  800]\n",
      "Epoch 62 / 100:\n",
      "Training Loss: 0.243811  [    0/  800]\n",
      "Training Loss: 0.257200  [  160/  800]\n",
      "Training Loss: 0.354362  [  320/  800]\n",
      "Training Loss: 0.336739  [  480/  800]\n",
      "Training Loss: 0.259935  [  640/  800]\n",
      "Epoch 63 / 100:\n",
      "Training Loss: 0.345732  [    0/  800]\n",
      "Training Loss: 0.276767  [  160/  800]\n",
      "Training Loss: 0.317700  [  320/  800]\n",
      "Training Loss: 0.387360  [  480/  800]\n",
      "Training Loss: 0.282881  [  640/  800]\n",
      "Epoch 64 / 100:\n",
      "Training Loss: 0.348702  [    0/  800]\n",
      "Training Loss: 0.287829  [  160/  800]\n",
      "Training Loss: 0.410345  [  320/  800]\n",
      "Training Loss: 0.357397  [  480/  800]\n",
      "Training Loss: 0.282056  [  640/  800]\n",
      "Epoch 65 / 100:\n",
      "Training Loss: 0.329559  [    0/  800]\n",
      "Training Loss: 0.460479  [  160/  800]\n",
      "Training Loss: 0.357962  [  320/  800]\n",
      "Training Loss: 0.273776  [  480/  800]\n",
      "Training Loss: 0.361982  [  640/  800]\n",
      "Epoch 66 / 100:\n",
      "Training Loss: 0.349468  [    0/  800]\n",
      "Training Loss: 0.380269  [  160/  800]\n",
      "Training Loss: 0.309127  [  320/  800]\n",
      "Training Loss: 0.270533  [  480/  800]\n",
      "Training Loss: 0.314864  [  640/  800]\n",
      "Epoch 67 / 100:\n",
      "Training Loss: 0.374145  [    0/  800]\n",
      "Training Loss: 0.365086  [  160/  800]\n",
      "Training Loss: 0.394673  [  320/  800]\n",
      "Training Loss: 0.244228  [  480/  800]\n",
      "Training Loss: 0.297799  [  640/  800]\n",
      "Epoch 68 / 100:\n",
      "Training Loss: 0.286115  [    0/  800]\n",
      "Training Loss: 0.419347  [  160/  800]\n",
      "Training Loss: 0.353343  [  320/  800]\n",
      "Training Loss: 0.217452  [  480/  800]\n",
      "Training Loss: 0.277911  [  640/  800]\n",
      "Epoch 69 / 100:\n",
      "Training Loss: 0.408181  [    0/  800]\n",
      "Training Loss: 0.360086  [  160/  800]\n",
      "Training Loss: 0.394548  [  320/  800]\n",
      "Training Loss: 0.341709  [  480/  800]\n",
      "Training Loss: 0.237089  [  640/  800]\n",
      "Epoch 70 / 100:\n",
      "Training Loss: 0.270093  [    0/  800]\n",
      "Training Loss: 0.427587  [  160/  800]\n",
      "Training Loss: 0.404223  [  320/  800]\n",
      "Training Loss: 0.296468  [  480/  800]\n",
      "Training Loss: 0.252384  [  640/  800]\n",
      "Epoch 71 / 100:\n",
      "Training Loss: 0.354120  [    0/  800]\n",
      "Training Loss: 0.329420  [  160/  800]\n",
      "Training Loss: 0.424153  [  320/  800]\n",
      "Training Loss: 0.272928  [  480/  800]\n",
      "Training Loss: 0.300370  [  640/  800]\n",
      "Epoch 72 / 100:\n",
      "Training Loss: 0.373780  [    0/  800]\n",
      "Training Loss: 0.326277  [  160/  800]\n",
      "Training Loss: 0.392422  [  320/  800]\n",
      "Training Loss: 0.277840  [  480/  800]\n",
      "Training Loss: 0.356644  [  640/  800]\n",
      "Epoch 73 / 100:\n",
      "Training Loss: 0.294951  [    0/  800]\n",
      "Training Loss: 0.323543  [  160/  800]\n",
      "Training Loss: 0.250450  [  320/  800]\n",
      "Training Loss: 0.351364  [  480/  800]\n",
      "Training Loss: 0.405633  [  640/  800]\n",
      "Epoch 74 / 100:\n",
      "Training Loss: 0.459632  [    0/  800]\n",
      "Training Loss: 0.310322  [  160/  800]\n",
      "Training Loss: 0.276230  [  320/  800]\n",
      "Training Loss: 0.388388  [  480/  800]\n",
      "Training Loss: 0.380533  [  640/  800]\n",
      "Epoch 75 / 100:\n",
      "Training Loss: 0.305550  [    0/  800]\n",
      "Training Loss: 0.339661  [  160/  800]\n",
      "Training Loss: 0.320559  [  320/  800]\n",
      "Training Loss: 0.303015  [  480/  800]\n",
      "Training Loss: 0.262153  [  640/  800]\n",
      "Epoch 76 / 100:\n",
      "Training Loss: 0.410780  [    0/  800]\n",
      "Training Loss: 0.257042  [  160/  800]\n",
      "Training Loss: 0.371982  [  320/  800]\n",
      "Training Loss: 0.359679  [  480/  800]\n",
      "Training Loss: 0.267913  [  640/  800]\n",
      "Epoch 77 / 100:\n",
      "Training Loss: 0.315868  [    0/  800]\n",
      "Training Loss: 0.301766  [  160/  800]\n",
      "Training Loss: 0.353563  [  320/  800]\n",
      "Training Loss: 0.172629  [  480/  800]\n",
      "Training Loss: 0.265775  [  640/  800]\n",
      "Epoch 78 / 100:\n",
      "Training Loss: 0.275898  [    0/  800]\n",
      "Training Loss: 0.342335  [  160/  800]\n",
      "Training Loss: 0.303950  [  320/  800]\n",
      "Training Loss: 0.380004  [  480/  800]\n",
      "Training Loss: 0.355911  [  640/  800]\n",
      "Epoch 79 / 100:\n",
      "Training Loss: 0.288531  [    0/  800]\n",
      "Training Loss: 0.390408  [  160/  800]\n",
      "Training Loss: 0.258542  [  320/  800]\n",
      "Training Loss: 0.253567  [  480/  800]\n",
      "Training Loss: 0.373257  [  640/  800]\n",
      "Epoch 80 / 100:\n",
      "Training Loss: 0.428798  [    0/  800]\n",
      "Training Loss: 0.288374  [  160/  800]\n",
      "Training Loss: 0.348099  [  320/  800]\n",
      "Training Loss: 0.337394  [  480/  800]\n",
      "Training Loss: 0.268057  [  640/  800]\n",
      "Epoch 81 / 100:\n",
      "Training Loss: 0.308734  [    0/  800]\n",
      "Training Loss: 0.371445  [  160/  800]\n",
      "Training Loss: 0.325064  [  320/  800]\n",
      "Training Loss: 0.337635  [  480/  800]\n",
      "Training Loss: 0.409614  [  640/  800]\n",
      "Epoch 82 / 100:\n",
      "Training Loss: 0.395911  [    0/  800]\n",
      "Training Loss: 0.357055  [  160/  800]\n",
      "Training Loss: 0.379359  [  320/  800]\n",
      "Training Loss: 0.314108  [  480/  800]\n",
      "Training Loss: 0.263119  [  640/  800]\n",
      "Epoch 83 / 100:\n",
      "Training Loss: 0.336384  [    0/  800]\n",
      "Training Loss: 0.379757  [  160/  800]\n",
      "Training Loss: 0.299907  [  320/  800]\n",
      "Training Loss: 0.339298  [  480/  800]\n",
      "Training Loss: 0.307258  [  640/  800]\n",
      "Epoch 84 / 100:\n",
      "Training Loss: 0.291410  [    0/  800]\n",
      "Training Loss: 0.454960  [  160/  800]\n",
      "Training Loss: 0.269048  [  320/  800]\n",
      "Training Loss: 0.341406  [  480/  800]\n",
      "Training Loss: 0.255267  [  640/  800]\n",
      "Epoch 85 / 100:\n",
      "Training Loss: 0.363306  [    0/  800]\n",
      "Training Loss: 0.282412  [  160/  800]\n",
      "Training Loss: 0.319172  [  320/  800]\n",
      "Training Loss: 0.305991  [  480/  800]\n",
      "Training Loss: 0.272391  [  640/  800]\n",
      "Epoch 86 / 100:\n",
      "Training Loss: 0.345151  [    0/  800]\n",
      "Training Loss: 0.409046  [  160/  800]\n",
      "Training Loss: 0.313706  [  320/  800]\n",
      "Training Loss: 0.455067  [  480/  800]\n",
      "Training Loss: 0.309724  [  640/  800]\n",
      "Epoch 87 / 100:\n",
      "Training Loss: 0.397127  [    0/  800]\n",
      "Training Loss: 0.342196  [  160/  800]\n",
      "Training Loss: 0.286807  [  320/  800]\n",
      "Training Loss: 0.226057  [  480/  800]\n",
      "Training Loss: 0.330014  [  640/  800]\n",
      "Epoch 88 / 100:\n",
      "Training Loss: 0.342045  [    0/  800]\n",
      "Training Loss: 0.413257  [  160/  800]\n",
      "Training Loss: 0.330774  [  320/  800]\n",
      "Training Loss: 0.332286  [  480/  800]\n",
      "Training Loss: 0.434099  [  640/  800]\n",
      "Epoch 89 / 100:\n",
      "Training Loss: 0.247099  [    0/  800]\n",
      "Training Loss: 0.374481  [  160/  800]\n",
      "Training Loss: 0.382787  [  320/  800]\n",
      "Training Loss: 0.332915  [  480/  800]\n",
      "Training Loss: 0.259826  [  640/  800]\n",
      "Epoch 90 / 100:\n",
      "Training Loss: 0.334176  [    0/  800]\n",
      "Training Loss: 0.333440  [  160/  800]\n",
      "Training Loss: 0.206157  [  320/  800]\n",
      "Training Loss: 0.419202  [  480/  800]\n",
      "Training Loss: 0.388394  [  640/  800]\n",
      "Epoch 91 / 100:\n",
      "Training Loss: 0.242424  [    0/  800]\n",
      "Training Loss: 0.343820  [  160/  800]\n",
      "Training Loss: 0.339635  [  320/  800]\n",
      "Training Loss: 0.392485  [  480/  800]\n",
      "Training Loss: 0.292032  [  640/  800]\n",
      "Epoch 92 / 100:\n",
      "Training Loss: 0.319946  [    0/  800]\n",
      "Training Loss: 0.386891  [  160/  800]\n",
      "Training Loss: 0.282378  [  320/  800]\n",
      "Training Loss: 0.324600  [  480/  800]\n",
      "Training Loss: 0.260847  [  640/  800]\n",
      "Epoch 93 / 100:\n",
      "Training Loss: 0.297248  [    0/  800]\n",
      "Training Loss: 0.273376  [  160/  800]\n",
      "Training Loss: 0.369669  [  320/  800]\n",
      "Training Loss: 0.266258  [  480/  800]\n",
      "Training Loss: 0.428404  [  640/  800]\n",
      "Epoch 94 / 100:\n",
      "Training Loss: 0.302136  [    0/  800]\n",
      "Training Loss: 0.363339  [  160/  800]\n",
      "Training Loss: 0.261796  [  320/  800]\n",
      "Training Loss: 0.308887  [  480/  800]\n",
      "Training Loss: 0.280606  [  640/  800]\n",
      "Epoch 95 / 100:\n",
      "Training Loss: 0.271021  [    0/  800]\n",
      "Training Loss: 0.388636  [  160/  800]\n",
      "Training Loss: 0.212278  [  320/  800]\n",
      "Training Loss: 0.303869  [  480/  800]\n",
      "Training Loss: 0.299170  [  640/  800]\n",
      "Epoch 96 / 100:\n",
      "Training Loss: 0.322685  [    0/  800]\n",
      "Training Loss: 0.300404  [  160/  800]\n",
      "Training Loss: 0.549384  [  320/  800]\n",
      "Training Loss: 0.352265  [  480/  800]\n",
      "Training Loss: 0.382476  [  640/  800]\n",
      "Epoch 97 / 100:\n",
      "Training Loss: 0.260521  [    0/  800]\n",
      "Training Loss: 0.250687  [  160/  800]\n",
      "Training Loss: 0.306290  [  320/  800]\n",
      "Training Loss: 0.363451  [  480/  800]\n",
      "Training Loss: 0.343724  [  640/  800]\n",
      "Epoch 98 / 100:\n",
      "Training Loss: 0.423249  [    0/  800]\n",
      "Training Loss: 0.283832  [  160/  800]\n",
      "Training Loss: 0.303104  [  320/  800]\n",
      "Training Loss: 0.339136  [  480/  800]\n",
      "Training Loss: 0.258781  [  640/  800]\n",
      "Epoch 99 / 100:\n",
      "Training Loss: 0.281187  [    0/  800]\n",
      "Training Loss: 0.258191  [  160/  800]\n",
      "Training Loss: 0.336122  [  320/  800]\n",
      "Training Loss: 0.353887  [  480/  800]\n",
      "Training Loss: 0.280518  [  640/  800]\n",
      "Epoch 100 / 100:\n",
      "Training Loss: 0.359945  [    0/  800]\n",
      "Training Loss: 0.335441  [  160/  800]\n",
      "Training Loss: 0.351378  [  320/  800]\n",
      "Training Loss: 0.246838  [  480/  800]\n",
      "Training Loss: 0.501291  [  640/  800]\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    print(f\"Epoch {epoch + 1} / {num_epoch}:\")\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data.to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        out_w, out_b = model(data)\n",
    "        loss = loss_fn(out_b, data.y_node) + loss_fn(out_w, data.y_edge)\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print status every n batches\n",
    "        if i % 10 == 0:\n",
    "            loss, current = loss.item(), i * batch_size\n",
    "            print(\n",
    "                f\"Training Loss: {loss:>7f}  [{current:>5d}/{train_num:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.244337\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    data = iter(test_loader).next().to(device)\n",
    "\n",
    "    # forward propagation\n",
    "    out_w, out_b = model(data)\n",
    "    loss = loss_fn(out_b, data.y_node) + loss_fn(out_w, data.y_edge)\n",
    "\n",
    "    loss = loss.item()\n",
    "    print(f\"Validation Loss: {loss:>7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  2., 14.], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = nndataset[0]\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_w, out_b = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"../model/model\")\n",
    "print(\"Model saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

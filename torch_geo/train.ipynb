{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Downloaded libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "# Local files\n",
    "from dataset_graphs import NNDataset\n",
    "from models import Trainer_GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging Settings\n",
    "torch.set_printoptions(threshold=12500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAINING_SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epoch = 8\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = None\n",
    "# transform = T.Compose([T.ToUndirected()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded, 1120 training samples and 280 testing samples\n"
     ]
    }
   ],
   "source": [
    "nndataset = NNDataset(root=\"../\", transform=transform)\n",
    "\n",
    "size = len(nndataset)\n",
    "train_num = int(size * TRAINING_SPLIT)\n",
    "test_num = size - train_num\n",
    "\n",
    "print(\n",
    "    f\"Dataset loaded, {train_num} training samples and {test_num} testing samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(design=[3], edge_index=[2, 40], x=[13, 503], edge_weight=[40, 1], y_node=[13, 1], y_edge=[40, 1], input_mask=[13, 1], num_nodes=13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of the Data\n",
    "\n",
    "data = nndataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=nndataset[:train_num], batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(\n",
    "    dataset=nndataset[train_num:], batch_size=test_num, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 140\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of batches:\", int(train_num / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Trainer_GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trainer_GCN(\n",
       "  (conv1): GATConv(503, 128, heads=1)\n",
       "  (conv2): GATConv(128, 128, heads=1)\n",
       "  (dense_1B): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dense_1W): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        data.to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        out_w, out_b = model(data)\n",
    "        loss = 0\n",
    "        loss += loss_fn(out_b, data.y_node)\n",
    "        loss += loss_fn(out_w, data.y_edge)\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print status every n batches\n",
    "        if i % 35 == 0:\n",
    "            loss, current = loss.item(), i * batch_size\n",
    "            print(\n",
    "                f\"Training Loss: {loss:>7f}  [{current:>5d}/{train_num:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = iter(dataloader).next().to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        out_w, out_b = model(data)\n",
    "        loss = loss_fn(out_b, data.y_node) + loss_fn(out_w, data.y_edge)\n",
    "\n",
    "        loss = loss.item()\n",
    "        print(f\"Validation Loss: {loss:>7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 8:\n",
      "Training Loss: 0.228955  [    0/ 1120]\n",
      "Training Loss: 0.184672  [  280/ 1120]\n",
      "Training Loss: 0.210227  [  560/ 1120]\n",
      "Training Loss: 0.135145  [  840/ 1120]\n",
      "Validation Loss: 0.122929\n",
      "Epoch 2 / 8:\n",
      "Training Loss: 0.128284  [    0/ 1120]\n",
      "Training Loss: 0.175270  [  280/ 1120]\n",
      "Training Loss: 0.137085  [  560/ 1120]\n",
      "Training Loss: 0.175932  [  840/ 1120]\n",
      "Validation Loss: 0.117009\n",
      "Epoch 3 / 8:\n",
      "Training Loss: 0.123424  [    0/ 1120]\n",
      "Training Loss: 0.157154  [  280/ 1120]\n",
      "Training Loss: 0.143915  [  560/ 1120]\n",
      "Training Loss: 0.128124  [  840/ 1120]\n",
      "Validation Loss: 0.115227\n",
      "Epoch 4 / 8:\n",
      "Training Loss: 0.141220  [    0/ 1120]\n",
      "Training Loss: 0.147863  [  280/ 1120]\n",
      "Training Loss: 0.184705  [  560/ 1120]\n",
      "Training Loss: 0.154989  [  840/ 1120]\n",
      "Validation Loss: 0.110405\n",
      "Epoch 5 / 8:\n",
      "Training Loss: 0.134065  [    0/ 1120]\n",
      "Training Loss: 0.145889  [  280/ 1120]\n",
      "Training Loss: 0.123261  [  560/ 1120]\n",
      "Training Loss: 0.144138  [  840/ 1120]\n",
      "Validation Loss: 0.108944\n",
      "Epoch 6 / 8:\n",
      "Training Loss: 0.136098  [    0/ 1120]\n",
      "Training Loss: 0.178572  [  280/ 1120]\n",
      "Training Loss: 0.156011  [  560/ 1120]\n",
      "Training Loss: 0.125897  [  840/ 1120]\n",
      "Validation Loss: 0.110629\n",
      "Epoch 7 / 8:\n",
      "Training Loss: 0.158781  [    0/ 1120]\n",
      "Training Loss: 0.141215  [  280/ 1120]\n",
      "Training Loss: 0.130484  [  560/ 1120]\n",
      "Training Loss: 0.157400  [  840/ 1120]\n",
      "Validation Loss: 0.112118\n",
      "Epoch 8 / 8:\n",
      "Training Loss: 0.140207  [    0/ 1120]\n",
      "Training Loss: 0.175726  [  280/ 1120]\n",
      "Training Loss: 0.132013  [  560/ 1120]\n",
      "Training Loss: 0.143119  [  840/ 1120]\n",
      "Validation Loss: 0.107348\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "for epoch in range(num_epoch):\n",
    "    print(f\"Epoch {epoch + 1} / {num_epoch}:\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Using One Instance of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(design=[3], edge_index=[2, 40], x=[13, 503], edge_weight=[40, 1], y_node=[13, 1], y_edge=[40, 1], input_mask=[13, 1], num_nodes=13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = nndataset[0]\n",
    "data = data.to(device)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 8, 2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_w, out_b = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0842],\n",
       "        [ 0.0837],\n",
       "        [ 0.0765],\n",
       "        [ 0.0744],\n",
       "        [ 0.0840],\n",
       "        [ 0.0822],\n",
       "        [ 0.0651],\n",
       "        [ 0.0848],\n",
       "        [-0.0181],\n",
       "        [-0.0187],\n",
       "        [-0.0258],\n",
       "        [-0.0282],\n",
       "        [-0.0183],\n",
       "        [-0.0202],\n",
       "        [-0.0374],\n",
       "        [-0.0177],\n",
       "        [ 0.0312],\n",
       "        [ 0.0307],\n",
       "        [ 0.0235],\n",
       "        [ 0.0212],\n",
       "        [ 0.0311],\n",
       "        [ 0.0292],\n",
       "        [ 0.0121],\n",
       "        [ 0.0318],\n",
       "        [-0.0037],\n",
       "        [-0.0051],\n",
       "        [-0.0041],\n",
       "        [-0.0055],\n",
       "        [-0.0113],\n",
       "        [-0.0127],\n",
       "        [-0.0136],\n",
       "        [-0.0150],\n",
       "        [-0.0038],\n",
       "        [-0.0052],\n",
       "        [-0.0057],\n",
       "        [-0.0071],\n",
       "        [-0.0228],\n",
       "        [-0.0242],\n",
       "        [-0.0032],\n",
       "        [-0.0046]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2277],\n",
       "        [-0.5283],\n",
       "        [ 0.0862],\n",
       "        [-0.3806],\n",
       "        [ 1.1312],\n",
       "        [-0.5555],\n",
       "        [-0.4393],\n",
       "        [-0.4372],\n",
       "        [ 1.0530],\n",
       "        [ 0.4600],\n",
       "        [-0.4602],\n",
       "        [-0.3724],\n",
       "        [-0.6324],\n",
       "        [-0.3388],\n",
       "        [-0.4321],\n",
       "        [-0.0846],\n",
       "        [ 0.3264],\n",
       "        [-0.4622],\n",
       "        [ 0.4405],\n",
       "        [ 0.3594],\n",
       "        [ 0.1728],\n",
       "        [-1.1223],\n",
       "        [ 0.6651],\n",
       "        [ 0.2089],\n",
       "        [-0.6755],\n",
       "        [ 0.5243],\n",
       "        [-0.4433],\n",
       "        [ 0.1207],\n",
       "        [ 0.5847],\n",
       "        [-0.5651],\n",
       "        [-0.0793],\n",
       "        [-0.0928],\n",
       "        [ 0.5919],\n",
       "        [-0.6201],\n",
       "        [-0.1842],\n",
       "        [ 0.6789],\n",
       "        [ 0.5201],\n",
       "        [-0.5449],\n",
       "        [ 0.1860],\n",
       "        [ 0.1699]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"../model/model\")\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

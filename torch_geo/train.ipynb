{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Downloaded libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "# Local files\n",
    "from dataset_graphs import NNDataset\n",
    "from models import Trainer_GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging Settings\n",
    "torch.set_printoptions(threshold=12500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAINING_SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epoch = 5\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = None\n",
    "# transform = T.Compose([T.ToUndirected()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded, 672 training samples and 168 testing samples\n"
     ]
    }
   ],
   "source": [
    "nndataset = NNDataset(root=\"../\", transform=transform)\n",
    "\n",
    "size = len(nndataset)\n",
    "train_num = int(size * TRAINING_SPLIT)\n",
    "test_num = size - train_num\n",
    "\n",
    "print(\n",
    "    f\"Dataset loaded, {train_num} training samples and {test_num} testing samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(design=[3], edge_index=[2, 480], x=[101, 503], edge_weight=[480, 1], y_node=[101, 1], y_edge=[480, 1], input_mask=[101, 1], num_nodes=101)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of the Data\n",
    "\n",
    "data = nndataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=nndataset[:train_num], batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(\n",
    "    dataset=nndataset[train_num:], batch_size=test_num, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 84\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of batches:\", int(train_num / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Trainer_GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trainer_GCN(\n",
       "  (conv1): GATConv(503, 128, heads=1)\n",
       "  (conv2): GATConv(128, 128, heads=1)\n",
       "  (dense_1B): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dense_1W): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        data.to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        out_w, out_b = model(data)\n",
    "        loss = 0\n",
    "        loss += loss_fn(out_b, data.y_node)\n",
    "        loss += loss_fn(out_w, data.y_edge)\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print status every n batches\n",
    "        if i % 35 == 0:\n",
    "            loss, current = loss.item(), i * batch_size\n",
    "            print(\n",
    "                f\"Training Loss: {loss:>7f}  [{current:>5d}/{train_num:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = iter(dataloader).next().to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        out_w, out_b = model(data)\n",
    "        loss = loss_fn(out_b, data.y_node) + loss_fn(out_w, data.y_edge)\n",
    "\n",
    "        loss = loss.item()\n",
    "        print(f\"Validation Loss: {loss:>7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 5:\n",
      "Training Loss: 0.335180  [    0/  672]\n",
      "Training Loss: 0.176350  [  280/  672]\n",
      "Training Loss: 0.151065  [  560/  672]\n",
      "Validation Loss: 0.135761\n",
      "Epoch 2 / 5:\n",
      "Training Loss: 0.163674  [    0/  672]\n",
      "Training Loss: 0.154293  [  280/  672]\n",
      "Training Loss: 0.141995  [  560/  672]\n",
      "Validation Loss: 0.141383\n",
      "Epoch 3 / 5:\n",
      "Training Loss: 0.150922  [    0/  672]\n",
      "Training Loss: 0.204343  [  280/  672]\n",
      "Training Loss: 0.186679  [  560/  672]\n",
      "Validation Loss: 0.122192\n",
      "Epoch 4 / 5:\n",
      "Training Loss: 0.177199  [    0/  672]\n",
      "Training Loss: 0.149488  [  280/  672]\n",
      "Training Loss: 0.187349  [  560/  672]\n",
      "Validation Loss: 0.129359\n",
      "Epoch 5 / 5:\n",
      "Training Loss: 0.133983  [    0/  672]\n",
      "Training Loss: 0.155119  [  280/  672]\n",
      "Training Loss: 0.123437  [  560/  672]\n",
      "Validation Loss: 0.118770\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "for epoch in range(num_epoch):\n",
    "    print(f\"Epoch {epoch + 1} / {num_epoch}:\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Using One Instance of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(design=[3], edge_index=[2, 480], x=[101, 503], edge_weight=[480, 1], y_node=[101, 1], y_edge=[480, 1], input_mask=[101, 1], num_nodes=101)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = nndataset[0]\n",
    "data = data.to(device)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_w, out_b = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0687],\n",
       "        [0.0846],\n",
       "        [0.0982],\n",
       "        [0.0769],\n",
       "        [0.0726],\n",
       "        [0.0891],\n",
       "        [0.0833],\n",
       "        [0.0696],\n",
       "        [0.0821],\n",
       "        [0.0983],\n",
       "        [0.0883],\n",
       "        [0.0723],\n",
       "        [0.0846],\n",
       "        [0.0756],\n",
       "        [0.0711],\n",
       "        [0.0864],\n",
       "        [0.0695],\n",
       "        [0.0969],\n",
       "        [0.0780],\n",
       "        [0.0768],\n",
       "        [0.0984],\n",
       "        [0.0980],\n",
       "        [0.0852],\n",
       "        [0.0719],\n",
       "        [0.0918],\n",
       "        [0.0758],\n",
       "        [0.0988],\n",
       "        [0.0725],\n",
       "        [0.0764],\n",
       "        [0.0728],\n",
       "        [0.0980],\n",
       "        [0.0827],\n",
       "        [0.0818],\n",
       "        [0.0842],\n",
       "        [0.0753],\n",
       "        [0.0756],\n",
       "        [0.0742],\n",
       "        [0.0689],\n",
       "        [0.0879],\n",
       "        [0.0809],\n",
       "        [0.0718],\n",
       "        [0.0901],\n",
       "        [0.0784],\n",
       "        [0.0963],\n",
       "        [0.0843],\n",
       "        [0.1008],\n",
       "        [0.0976],\n",
       "        [0.0991],\n",
       "        [0.1008],\n",
       "        [0.0953],\n",
       "        [0.0745],\n",
       "        [0.0810],\n",
       "        [0.0860],\n",
       "        [0.0986],\n",
       "        [0.0920],\n",
       "        [0.0839],\n",
       "        [0.0737],\n",
       "        [0.0827],\n",
       "        [0.0712],\n",
       "        [0.0688],\n",
       "        [0.0850],\n",
       "        [0.0712],\n",
       "        [0.0746],\n",
       "        [0.0717],\n",
       "        [0.1003],\n",
       "        [0.0935],\n",
       "        [0.0687],\n",
       "        [0.0823],\n",
       "        [0.0879],\n",
       "        [0.0822],\n",
       "        [0.0738],\n",
       "        [0.0716],\n",
       "        [0.0870],\n",
       "        [0.0762],\n",
       "        [0.0827],\n",
       "        [0.0932],\n",
       "        [0.1005],\n",
       "        [0.0918],\n",
       "        [0.0718],\n",
       "        [0.0971],\n",
       "        [0.0949],\n",
       "        [0.0935],\n",
       "        [0.0834],\n",
       "        [0.0757],\n",
       "        [0.0826],\n",
       "        [0.0701],\n",
       "        [0.0764],\n",
       "        [0.0776],\n",
       "        [0.0801],\n",
       "        [0.0989],\n",
       "        [0.0838],\n",
       "        [0.0845],\n",
       "        [0.0739],\n",
       "        [0.0805],\n",
       "        [0.0801],\n",
       "        [0.0990],\n",
       "        [0.0279],\n",
       "        [0.0438],\n",
       "        [0.0573],\n",
       "        [0.0361],\n",
       "        [0.0320],\n",
       "        [0.0483],\n",
       "        [0.0425],\n",
       "        [0.0287],\n",
       "        [0.0411],\n",
       "        [0.0573],\n",
       "        [0.0475],\n",
       "        [0.0314],\n",
       "        [0.0435],\n",
       "        [0.0347],\n",
       "        [0.0300],\n",
       "        [0.0459],\n",
       "        [0.0288],\n",
       "        [0.0561],\n",
       "        [0.0370],\n",
       "        [0.0361],\n",
       "        [0.0575],\n",
       "        [0.0571],\n",
       "        [0.0443],\n",
       "        [0.0311],\n",
       "        [0.0508],\n",
       "        [0.0350],\n",
       "        [0.0578],\n",
       "        [0.0316],\n",
       "        [0.0355],\n",
       "        [0.0321],\n",
       "        [0.0570],\n",
       "        [0.0421],\n",
       "        [0.0409],\n",
       "        [0.0433],\n",
       "        [0.0345],\n",
       "        [0.0346],\n",
       "        [0.0334],\n",
       "        [0.0280],\n",
       "        [0.0470],\n",
       "        [0.0402],\n",
       "        [0.0311],\n",
       "        [0.0492],\n",
       "        [0.0375],\n",
       "        [0.0555],\n",
       "        [0.0434],\n",
       "        [0.0599],\n",
       "        [0.0567],\n",
       "        [0.0583],\n",
       "        [0.0599],\n",
       "        [0.0543],\n",
       "        [0.0336],\n",
       "        [0.0402],\n",
       "        [0.0450],\n",
       "        [0.0578],\n",
       "        [0.0510],\n",
       "        [0.0432],\n",
       "        [0.0329],\n",
       "        [0.0418],\n",
       "        [0.0302],\n",
       "        [0.0277],\n",
       "        [0.0441],\n",
       "        [0.0303],\n",
       "        [0.0338],\n",
       "        [0.0308],\n",
       "        [0.0595],\n",
       "        [0.0526],\n",
       "        [0.0278],\n",
       "        [0.0415],\n",
       "        [0.0470],\n",
       "        [0.0412],\n",
       "        [0.0329],\n",
       "        [0.0306],\n",
       "        [0.0461],\n",
       "        [0.0353],\n",
       "        [0.0418],\n",
       "        [0.0523],\n",
       "        [0.0596],\n",
       "        [0.0508],\n",
       "        [0.0310],\n",
       "        [0.0562],\n",
       "        [0.0539],\n",
       "        [0.0528],\n",
       "        [0.0424],\n",
       "        [0.0348],\n",
       "        [0.0418],\n",
       "        [0.0293],\n",
       "        [0.0354],\n",
       "        [0.0367],\n",
       "        [0.0393],\n",
       "        [0.0581],\n",
       "        [0.0430],\n",
       "        [0.0435],\n",
       "        [0.0331],\n",
       "        [0.0396],\n",
       "        [0.0392],\n",
       "        [0.0581],\n",
       "        [0.0195],\n",
       "        [0.0353],\n",
       "        [0.0488],\n",
       "        [0.0277],\n",
       "        [0.0235],\n",
       "        [0.0399],\n",
       "        [0.0339],\n",
       "        [0.0204],\n",
       "        [0.0328],\n",
       "        [0.0490],\n",
       "        [0.0390],\n",
       "        [0.0230],\n",
       "        [0.0353],\n",
       "        [0.0263],\n",
       "        [0.0219],\n",
       "        [0.0374],\n",
       "        [0.0206],\n",
       "        [0.0476],\n",
       "        [0.0287],\n",
       "        [0.0276],\n",
       "        [0.0492],\n",
       "        [0.0488],\n",
       "        [0.0359],\n",
       "        [0.0229],\n",
       "        [0.0426],\n",
       "        [0.0266],\n",
       "        [0.0492],\n",
       "        [0.0233],\n",
       "        [0.0272],\n",
       "        [0.0237],\n",
       "        [0.0487],\n",
       "        [0.0337],\n",
       "        [0.0325],\n",
       "        [0.0351],\n",
       "        [0.0261],\n",
       "        [0.0262],\n",
       "        [0.0250],\n",
       "        [0.0197],\n",
       "        [0.0386],\n",
       "        [0.0318],\n",
       "        [0.0227],\n",
       "        [0.0408],\n",
       "        [0.0292],\n",
       "        [0.0470],\n",
       "        [0.0351],\n",
       "        [0.0517],\n",
       "        [0.0482],\n",
       "        [0.0498],\n",
       "        [0.0515],\n",
       "        [0.0462],\n",
       "        [0.0251],\n",
       "        [0.0316],\n",
       "        [0.0368],\n",
       "        [0.0493],\n",
       "        [0.0427],\n",
       "        [0.0347],\n",
       "        [0.0246],\n",
       "        [0.0336],\n",
       "        [0.0219],\n",
       "        [0.0194],\n",
       "        [0.0359],\n",
       "        [0.0218],\n",
       "        [0.0253],\n",
       "        [0.0224],\n",
       "        [0.0511],\n",
       "        [0.0441],\n",
       "        [0.0193],\n",
       "        [0.0332],\n",
       "        [0.0385],\n",
       "        [0.0329],\n",
       "        [0.0246],\n",
       "        [0.0222],\n",
       "        [0.0377],\n",
       "        [0.0270],\n",
       "        [0.0335],\n",
       "        [0.0440],\n",
       "        [0.0514],\n",
       "        [0.0426],\n",
       "        [0.0228],\n",
       "        [0.0478],\n",
       "        [0.0456],\n",
       "        [0.0445],\n",
       "        [0.0340],\n",
       "        [0.0265],\n",
       "        [0.0333],\n",
       "        [0.0209],\n",
       "        [0.0270],\n",
       "        [0.0284],\n",
       "        [0.0309],\n",
       "        [0.0496],\n",
       "        [0.0346],\n",
       "        [0.0353],\n",
       "        [0.0248],\n",
       "        [0.0311],\n",
       "        [0.0309],\n",
       "        [0.0496],\n",
       "        [0.0160],\n",
       "        [0.0158],\n",
       "        [0.0318],\n",
       "        [0.0317],\n",
       "        [0.0454],\n",
       "        [0.0452],\n",
       "        [0.0242],\n",
       "        [0.0241],\n",
       "        [0.0200],\n",
       "        [0.0199],\n",
       "        [0.0364],\n",
       "        [0.0363],\n",
       "        [0.0305],\n",
       "        [0.0303],\n",
       "        [0.0169],\n",
       "        [0.0167],\n",
       "        [0.0292],\n",
       "        [0.0291],\n",
       "        [0.0454],\n",
       "        [0.0453],\n",
       "        [0.0355],\n",
       "        [0.0354],\n",
       "        [0.0195],\n",
       "        [0.0194],\n",
       "        [0.0317],\n",
       "        [0.0316],\n",
       "        [0.0228],\n",
       "        [0.0227],\n",
       "        [0.0182],\n",
       "        [0.0181],\n",
       "        [0.0338],\n",
       "        [0.0337],\n",
       "        [0.0170],\n",
       "        [0.0168],\n",
       "        [0.0442],\n",
       "        [0.0441],\n",
       "        [0.0250],\n",
       "        [0.0250],\n",
       "        [0.0241],\n",
       "        [0.0240],\n",
       "        [0.0456],\n",
       "        [0.0455],\n",
       "        [0.0452],\n",
       "        [0.0451],\n",
       "        [0.0324],\n",
       "        [0.0323],\n",
       "        [0.0192],\n",
       "        [0.0191],\n",
       "        [0.0390],\n",
       "        [0.0388],\n",
       "        [0.0231],\n",
       "        [0.0230],\n",
       "        [0.0458],\n",
       "        [0.0457],\n",
       "        [0.0198],\n",
       "        [0.0196],\n",
       "        [0.0236],\n",
       "        [0.0235],\n",
       "        [0.0202],\n",
       "        [0.0201],\n",
       "        [0.0452],\n",
       "        [0.0451],\n",
       "        [0.0302],\n",
       "        [0.0300],\n",
       "        [0.0290],\n",
       "        [0.0288],\n",
       "        [0.0316],\n",
       "        [0.0314],\n",
       "        [0.0226],\n",
       "        [0.0225],\n",
       "        [0.0228],\n",
       "        [0.0226],\n",
       "        [0.0215],\n",
       "        [0.0214],\n",
       "        [0.0161],\n",
       "        [0.0160],\n",
       "        [0.0351],\n",
       "        [0.0350],\n",
       "        [0.0282],\n",
       "        [0.0281],\n",
       "        [0.0192],\n",
       "        [0.0190],\n",
       "        [0.0372],\n",
       "        [0.0371],\n",
       "        [0.0257],\n",
       "        [0.0255],\n",
       "        [0.0435],\n",
       "        [0.0434],\n",
       "        [0.0315],\n",
       "        [0.0314],\n",
       "        [0.0481],\n",
       "        [0.0479],\n",
       "        [0.0448],\n",
       "        [0.0447],\n",
       "        [0.0463],\n",
       "        [0.0462],\n",
       "        [0.0479],\n",
       "        [0.0478],\n",
       "        [0.0426],\n",
       "        [0.0424],\n",
       "        [0.0216],\n",
       "        [0.0215],\n",
       "        [0.0283],\n",
       "        [0.0281],\n",
       "        [0.0332],\n",
       "        [0.0331],\n",
       "        [0.0459],\n",
       "        [0.0458],\n",
       "        [0.0392],\n",
       "        [0.0391],\n",
       "        [0.0312],\n",
       "        [0.0310],\n",
       "        [0.0210],\n",
       "        [0.0209],\n",
       "        [0.0299],\n",
       "        [0.0299],\n",
       "        [0.0182],\n",
       "        [0.0181],\n",
       "        [0.0159],\n",
       "        [0.0159],\n",
       "        [0.0322],\n",
       "        [0.0321],\n",
       "        [0.0183],\n",
       "        [0.0181],\n",
       "        [0.0218],\n",
       "        [0.0217],\n",
       "        [0.0189],\n",
       "        [0.0188],\n",
       "        [0.0476],\n",
       "        [0.0475],\n",
       "        [0.0407],\n",
       "        [0.0405],\n",
       "        [0.0159],\n",
       "        [0.0158],\n",
       "        [0.0297],\n",
       "        [0.0295],\n",
       "        [0.0351],\n",
       "        [0.0350],\n",
       "        [0.0294],\n",
       "        [0.0292],\n",
       "        [0.0210],\n",
       "        [0.0209],\n",
       "        [0.0188],\n",
       "        [0.0186],\n",
       "        [0.0342],\n",
       "        [0.0341],\n",
       "        [0.0234],\n",
       "        [0.0233],\n",
       "        [0.0299],\n",
       "        [0.0298],\n",
       "        [0.0405],\n",
       "        [0.0403],\n",
       "        [0.0478],\n",
       "        [0.0476],\n",
       "        [0.0390],\n",
       "        [0.0389],\n",
       "        [0.0191],\n",
       "        [0.0190],\n",
       "        [0.0443],\n",
       "        [0.0442],\n",
       "        [0.0421],\n",
       "        [0.0420],\n",
       "        [0.0409],\n",
       "        [0.0408],\n",
       "        [0.0305],\n",
       "        [0.0304],\n",
       "        [0.0229],\n",
       "        [0.0228],\n",
       "        [0.0299],\n",
       "        [0.0297],\n",
       "        [0.0173],\n",
       "        [0.0172],\n",
       "        [0.0235],\n",
       "        [0.0234],\n",
       "        [0.0248],\n",
       "        [0.0247],\n",
       "        [0.0274],\n",
       "        [0.0273],\n",
       "        [0.0462],\n",
       "        [0.0461],\n",
       "        [0.0311],\n",
       "        [0.0310],\n",
       "        [0.0317],\n",
       "        [0.0316],\n",
       "        [0.0212],\n",
       "        [0.0211],\n",
       "        [0.0277],\n",
       "        [0.0276],\n",
       "        [0.0274],\n",
       "        [0.0273],\n",
       "        [0.0462],\n",
       "        [0.0461]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.7527e-01],\n",
       "        [ 3.7460e-01],\n",
       "        [-1.6935e-01],\n",
       "        [ 2.0094e-01],\n",
       "        [ 2.4731e-01],\n",
       "        [ 7.2946e-01],\n",
       "        [ 7.7207e-01],\n",
       "        [ 1.5824e-02],\n",
       "        [-2.5034e-01],\n",
       "        [-4.8785e-02],\n",
       "        [-6.3134e-01],\n",
       "        [ 7.9112e-01],\n",
       "        [-1.7706e-01],\n",
       "        [ 3.0932e-01],\n",
       "        [ 9.2282e-02],\n",
       "        [ 1.6429e-01],\n",
       "        [ 3.1813e-01],\n",
       "        [ 5.8020e-01],\n",
       "        [ 3.4108e-02],\n",
       "        [ 8.7037e-01],\n",
       "        [-4.0597e-01],\n",
       "        [-1.3940e-01],\n",
       "        [-4.1489e-02],\n",
       "        [ 7.2107e-01],\n",
       "        [-6.0859e-01],\n",
       "        [-3.5519e-01],\n",
       "        [ 6.1911e-01],\n",
       "        [ 8.3324e-02],\n",
       "        [-4.2840e-01],\n",
       "        [-2.2025e-01],\n",
       "        [ 2.9421e-01],\n",
       "        [ 3.9168e-01],\n",
       "        [ 6.7508e-01],\n",
       "        [-4.4235e-01],\n",
       "        [-6.3572e-01],\n",
       "        [-6.6365e-01],\n",
       "        [ 5.1898e-01],\n",
       "        [-9.0155e-02],\n",
       "        [-3.5181e-01],\n",
       "        [-7.2123e-02],\n",
       "        [ 3.7966e-01],\n",
       "        [ 7.0443e-01],\n",
       "        [ 2.2730e-01],\n",
       "        [-3.8037e-01],\n",
       "        [ 5.1758e-01],\n",
       "        [ 5.5116e-02],\n",
       "        [ 3.8670e-01],\n",
       "        [-3.1081e-01],\n",
       "        [-4.5428e-01],\n",
       "        [ 1.5556e-01],\n",
       "        [-2.7029e-01],\n",
       "        [ 2.7530e-01],\n",
       "        [-7.0027e-02],\n",
       "        [-5.0217e-01],\n",
       "        [ 6.8936e-01],\n",
       "        [-4.9125e-01],\n",
       "        [-1.6848e-01],\n",
       "        [ 7.6739e-01],\n",
       "        [ 4.8568e-01],\n",
       "        [ 6.5371e-01],\n",
       "        [ 2.7140e-01],\n",
       "        [ 6.0799e-01],\n",
       "        [-5.1527e-01],\n",
       "        [ 8.8661e-02],\n",
       "        [-3.5914e-01],\n",
       "        [ 7.9349e-01],\n",
       "        [-1.3218e-01],\n",
       "        [ 7.6969e-01],\n",
       "        [-5.6754e-01],\n",
       "        [-5.0578e-01],\n",
       "        [ 1.2316e-01],\n",
       "        [-4.6547e-01],\n",
       "        [-6.7435e-01],\n",
       "        [ 3.9463e-01],\n",
       "        [-3.7306e-01],\n",
       "        [-5.6961e-01],\n",
       "        [ 4.8525e-01],\n",
       "        [ 6.5030e-01],\n",
       "        [-5.7172e-02],\n",
       "        [-4.0199e-01],\n",
       "        [ 2.4427e-01],\n",
       "        [ 1.3371e-02],\n",
       "        [-6.5179e-01],\n",
       "        [-2.1703e-01],\n",
       "        [-3.0037e-01],\n",
       "        [-4.1446e-01],\n",
       "        [ 7.9647e-01],\n",
       "        [-2.2843e-01],\n",
       "        [ 4.8183e-01],\n",
       "        [-9.9554e-02],\n",
       "        [ 1.1975e-01],\n",
       "        [-1.0101e-01],\n",
       "        [ 8.4997e-02],\n",
       "        [ 3.3362e-01],\n",
       "        [ 8.2461e-01],\n",
       "        [ 5.5594e-01],\n",
       "        [ 7.3076e-01],\n",
       "        [ 8.0229e-01],\n",
       "        [ 3.5954e-01],\n",
       "        [ 3.7937e-01],\n",
       "        [ 3.4736e-01],\n",
       "        [ 2.3612e-01],\n",
       "        [-5.6061e-01],\n",
       "        [ 3.2993e-01],\n",
       "        [-4.2548e-01],\n",
       "        [ 9.3219e-02],\n",
       "        [ 1.4991e-02],\n",
       "        [-3.7235e-01],\n",
       "        [ 6.6199e-01],\n",
       "        [ 5.5469e-01],\n",
       "        [-5.2120e-01],\n",
       "        [-4.1857e-02],\n",
       "        [ 1.2056e-01],\n",
       "        [ 3.1377e-01],\n",
       "        [ 5.3783e-01],\n",
       "        [-6.1758e-01],\n",
       "        [-3.7523e-01],\n",
       "        [-2.4208e-01],\n",
       "        [ 5.7353e-01],\n",
       "        [-5.9467e-01],\n",
       "        [ 3.6565e-01],\n",
       "        [ 1.4624e-03],\n",
       "        [-7.2762e-01],\n",
       "        [ 5.0340e-01],\n",
       "        [-8.6589e-02],\n",
       "        [ 2.4135e-01],\n",
       "        [ 1.4274e-01],\n",
       "        [ 6.2082e-01],\n",
       "        [-3.5807e-01],\n",
       "        [ 2.0676e-01],\n",
       "        [ 1.1952e-01],\n",
       "        [-5.5363e-02],\n",
       "        [ 6.6160e-01],\n",
       "        [-2.2870e-01],\n",
       "        [ 4.4220e-01],\n",
       "        [-4.3136e-01],\n",
       "        [ 6.8939e-01],\n",
       "        [-3.8908e-01],\n",
       "        [ 7.3628e-01],\n",
       "        [-5.1321e-01],\n",
       "        [-4.9740e-01],\n",
       "        [ 4.9781e-01],\n",
       "        [-4.9841e-01],\n",
       "        [-3.2045e-02],\n",
       "        [-3.9701e-01],\n",
       "        [ 5.6867e-01],\n",
       "        [-3.6829e-02],\n",
       "        [ 6.1515e-02],\n",
       "        [-4.0837e-01],\n",
       "        [-5.1788e-01],\n",
       "        [-5.6481e-01],\n",
       "        [-6.4694e-02],\n",
       "        [-6.7419e-01],\n",
       "        [-5.5247e-01],\n",
       "        [-6.7096e-02],\n",
       "        [-7.1666e-02],\n",
       "        [ 6.6419e-01],\n",
       "        [-1.4619e-01],\n",
       "        [-2.0031e-01],\n",
       "        [-1.7954e-01],\n",
       "        [ 2.3841e-01],\n",
       "        [-5.1042e-01],\n",
       "        [ 2.8069e-01],\n",
       "        [-5.7538e-01],\n",
       "        [ 3.9678e-02],\n",
       "        [ 1.0588e-01],\n",
       "        [ 5.4774e-01],\n",
       "        [ 3.7749e-01],\n",
       "        [ 4.9317e-01],\n",
       "        [ 5.4350e-01],\n",
       "        [ 8.2287e-02],\n",
       "        [-2.3024e-01],\n",
       "        [ 5.4570e-01],\n",
       "        [ 5.4477e-02],\n",
       "        [ 3.8416e-02],\n",
       "        [-4.4213e-01],\n",
       "        [ 6.1198e-01],\n",
       "        [ 5.2873e-01],\n",
       "        [ 2.4096e-01],\n",
       "        [-4.7133e-01],\n",
       "        [ 3.3028e-02],\n",
       "        [ 2.6998e-01],\n",
       "        [ 3.1757e-01],\n",
       "        [ 2.1463e-01],\n",
       "        [ 6.1971e-01],\n",
       "        [-6.6013e-02],\n",
       "        [ 7.3965e-01],\n",
       "        [-6.4304e-01],\n",
       "        [-1.7910e-01],\n",
       "        [ 7.9176e-01],\n",
       "        [-2.9359e-01],\n",
       "        [ 5.2787e-01],\n",
       "        [-8.4490e-02],\n",
       "        [ 5.2011e-01],\n",
       "        [ 8.2910e-04],\n",
       "        [-8.5164e-02],\n",
       "        [-3.3155e-01],\n",
       "        [-1.4472e-02],\n",
       "        [ 1.6116e-01],\n",
       "        [-4.2947e-01],\n",
       "        [-4.2888e-01],\n",
       "        [-2.9604e-01],\n",
       "        [ 3.9760e-01],\n",
       "        [-3.0133e-01],\n",
       "        [-4.6505e-02],\n",
       "        [ 1.6931e-01],\n",
       "        [ 3.9370e-01],\n",
       "        [-4.1396e-01],\n",
       "        [-3.4882e-01],\n",
       "        [-2.2839e-01],\n",
       "        [ 3.5481e-01],\n",
       "        [ 1.9620e-01],\n",
       "        [-3.9680e-01],\n",
       "        [ 4.5089e-01],\n",
       "        [ 6.2055e-04],\n",
       "        [ 4.7475e-01],\n",
       "        [-1.6148e-01],\n",
       "        [-1.7094e-01],\n",
       "        [ 4.7609e-01],\n",
       "        [-2.2215e-01],\n",
       "        [-9.2395e-02],\n",
       "        [-2.9241e-01],\n",
       "        [ 5.1636e-01],\n",
       "        [ 4.9032e-01],\n",
       "        [-2.3555e-01],\n",
       "        [ 5.9086e-01],\n",
       "        [-2.4430e-01],\n",
       "        [ 5.2247e-01],\n",
       "        [ 4.1658e-01],\n",
       "        [ 4.2714e-01],\n",
       "        [ 3.5562e-01],\n",
       "        [ 2.6875e-01],\n",
       "        [ 5.9740e-02],\n",
       "        [ 3.0157e-01],\n",
       "        [ 3.3536e-01],\n",
       "        [-4.2111e-01],\n",
       "        [ 3.2836e-01],\n",
       "        [ 5.2687e-01],\n",
       "        [ 4.4102e-01],\n",
       "        [ 2.9598e-01],\n",
       "        [-4.5403e-01],\n",
       "        [ 6.0720e-01],\n",
       "        [-5.1974e-01],\n",
       "        [ 2.9402e-01],\n",
       "        [-5.1458e-01],\n",
       "        [-6.9163e-01],\n",
       "        [-3.9274e-01],\n",
       "        [-1.3663e-01],\n",
       "        [ 2.1232e-01],\n",
       "        [ 2.8682e-01],\n",
       "        [-6.2463e-01],\n",
       "        [ 1.4780e-01],\n",
       "        [ 5.1306e-01],\n",
       "        [ 3.8503e-01],\n",
       "        [ 5.1397e-02],\n",
       "        [ 5.8048e-02],\n",
       "        [-6.0455e-01],\n",
       "        [-4.7256e-02],\n",
       "        [-3.1903e-01],\n",
       "        [ 1.5427e-01],\n",
       "        [-1.0509e-01],\n",
       "        [ 5.7237e-01],\n",
       "        [-3.4974e-01],\n",
       "        [ 2.0578e-02],\n",
       "        [-1.2539e-01],\n",
       "        [ 2.9404e-01],\n",
       "        [ 5.2340e-02],\n",
       "        [ 1.6261e-01],\n",
       "        [ 1.2570e-01],\n",
       "        [ 9.9606e-02],\n",
       "        [-5.2609e-01],\n",
       "        [-5.8724e-01],\n",
       "        [-1.8901e-01],\n",
       "        [-2.3813e-01],\n",
       "        [ 3.9098e-01],\n",
       "        [-2.9144e-01],\n",
       "        [-5.2826e-01],\n",
       "        [-4.7822e-01],\n",
       "        [-1.1136e-01],\n",
       "        [-1.7861e-01],\n",
       "        [ 5.9445e-01],\n",
       "        [-5.7957e-01],\n",
       "        [ 2.2981e-01],\n",
       "        [-6.5496e-01],\n",
       "        [-3.1594e-01],\n",
       "        [ 5.6819e-01],\n",
       "        [-1.4097e-01],\n",
       "        [ 3.0396e-02],\n",
       "        [-2.3282e-01],\n",
       "        [ 2.4185e-01],\n",
       "        [-1.8982e-01],\n",
       "        [ 2.6542e-01],\n",
       "        [ 1.1954e-01],\n",
       "        [-1.6970e-01],\n",
       "        [-2.6667e-01],\n",
       "        [ 2.5683e-01],\n",
       "        [-3.6776e-02],\n",
       "        [ 2.9906e-02],\n",
       "        [ 1.9762e-01],\n",
       "        [-2.2232e-01],\n",
       "        [ 1.6254e-01],\n",
       "        [-2.9612e-01],\n",
       "        [-1.5025e-01],\n",
       "        [ 1.8725e-01],\n",
       "        [-1.9435e-02],\n",
       "        [ 8.5928e-02],\n",
       "        [-9.9662e-02],\n",
       "        [ 1.3848e-02],\n",
       "        [ 1.1071e-01],\n",
       "        [-1.9948e-01],\n",
       "        [ 2.0146e-01],\n",
       "        [-2.8422e-01],\n",
       "        [ 3.6019e-02],\n",
       "        [ 1.1474e-01],\n",
       "        [-2.9818e-01],\n",
       "        [ 3.0973e-01],\n",
       "        [ 4.4349e-02],\n",
       "        [ 2.4702e-02],\n",
       "        [ 2.4890e-02],\n",
       "        [-7.1984e-02],\n",
       "        [-6.3993e-02],\n",
       "        [-1.0791e-02],\n",
       "        [ 1.7778e-01],\n",
       "        [-2.8612e-01],\n",
       "        [-7.0595e-02],\n",
       "        [ 7.1450e-02],\n",
       "        [ 2.2926e-01],\n",
       "        [-1.2660e-01],\n",
       "        [-1.2251e-01],\n",
       "        [ 2.1948e-01],\n",
       "        [ 1.9841e-01],\n",
       "        [-3.2574e-01],\n",
       "        [-2.7912e-02],\n",
       "        [ 1.4815e-01],\n",
       "        [ 1.3620e-01],\n",
       "        [-2.3338e-01],\n",
       "        [ 2.9604e-01],\n",
       "        [-2.4445e-01],\n",
       "        [-1.4525e-02],\n",
       "        [ 9.6770e-02],\n",
       "        [ 2.1117e-01],\n",
       "        [-2.2238e-01],\n",
       "        [-2.1385e-01],\n",
       "        [ 9.7596e-02],\n",
       "        [ 2.3564e-02],\n",
       "        [-5.1346e-02],\n",
       "        [-1.1664e-01],\n",
       "        [ 8.4068e-02],\n",
       "        [ 1.7703e-03],\n",
       "        [ 6.6837e-02],\n",
       "        [-1.7568e-01],\n",
       "        [ 2.6915e-01],\n",
       "        [ 2.5872e-01],\n",
       "        [-3.2033e-01],\n",
       "        [ 7.4049e-02],\n",
       "        [-1.3768e-01],\n",
       "        [ 3.7912e-02],\n",
       "        [-9.8799e-02],\n",
       "        [ 1.3151e-01],\n",
       "        [-6.8235e-02],\n",
       "        [-2.7237e-01],\n",
       "        [ 2.0784e-01],\n",
       "        [-1.2947e-02],\n",
       "        [ 1.2807e-02],\n",
       "        [-1.8041e-02],\n",
       "        [-3.1379e-02],\n",
       "        [ 1.7096e-01],\n",
       "        [-1.9627e-01],\n",
       "        [-2.5626e-01],\n",
       "        [ 3.1853e-01],\n",
       "        [ 1.7616e-01],\n",
       "        [-2.6687e-01],\n",
       "        [-2.2489e-01],\n",
       "        [ 1.4143e-01],\n",
       "        [-2.4504e-01],\n",
       "        [ 2.0257e-01],\n",
       "        [ 1.0348e-01],\n",
       "        [-2.4538e-01],\n",
       "        [-1.2246e-01],\n",
       "        [ 1.4650e-01],\n",
       "        [ 2.6965e-01],\n",
       "        [-2.0031e-01],\n",
       "        [ 1.6097e-01],\n",
       "        [-1.8331e-01],\n",
       "        [-8.1926e-02],\n",
       "        [ 2.5835e-01],\n",
       "        [-1.6112e-01],\n",
       "        [ 2.4183e-02],\n",
       "        [ 7.9105e-03],\n",
       "        [ 4.7579e-02],\n",
       "        [ 3.3068e-02],\n",
       "        [ 4.1869e-02],\n",
       "        [-1.7088e-01],\n",
       "        [ 1.1876e-01],\n",
       "        [-2.2452e-01],\n",
       "        [ 1.6449e-01],\n",
       "        [ 2.2977e-01],\n",
       "        [-2.1966e-01],\n",
       "        [ 3.6462e-02],\n",
       "        [ 1.8055e-03],\n",
       "        [ 1.7206e-01],\n",
       "        [-5.9205e-02],\n",
       "        [ 1.0194e-01],\n",
       "        [-2.6390e-01],\n",
       "        [ 3.2264e-02],\n",
       "        [-3.2791e-02],\n",
       "        [ 6.6907e-02],\n",
       "        [-1.5906e-01],\n",
       "        [-2.1897e-01],\n",
       "        [ 1.2287e-01],\n",
       "        [ 1.2296e-01],\n",
       "        [-4.6031e-02],\n",
       "        [ 7.4621e-02],\n",
       "        [-3.0677e-03],\n",
       "        [-5.0317e-02],\n",
       "        [ 3.9291e-02],\n",
       "        [ 1.6337e-01],\n",
       "        [-2.1378e-01],\n",
       "        [ 3.3041e-01],\n",
       "        [-2.4670e-01],\n",
       "        [-1.0440e-01],\n",
       "        [ 1.8712e-01],\n",
       "        [ 1.1001e-01],\n",
       "        [-1.4763e-01],\n",
       "        [ 3.2706e-02],\n",
       "        [-1.2410e-01],\n",
       "        [ 1.6590e-01],\n",
       "        [-1.9391e-01],\n",
       "        [-5.6143e-02],\n",
       "        [ 2.0887e-01],\n",
       "        [-1.6458e-02],\n",
       "        [-3.5153e-02],\n",
       "        [ 3.8635e-02],\n",
       "        [-1.7875e-01],\n",
       "        [-1.6023e-01],\n",
       "        [ 1.5039e-01],\n",
       "        [ 4.0242e-03],\n",
       "        [ 2.8945e-03],\n",
       "        [ 1.9784e-01],\n",
       "        [-1.9652e-01],\n",
       "        [ 2.8212e-01],\n",
       "        [-3.9483e-01],\n",
       "        [ 2.0584e-01],\n",
       "        [-2.4739e-01],\n",
       "        [-1.6425e-01],\n",
       "        [ 2.0239e-02],\n",
       "        [-1.1335e-01],\n",
       "        [ 1.3921e-01],\n",
       "        [ 3.0096e-01],\n",
       "        [-1.6264e-01],\n",
       "        [-6.0848e-02],\n",
       "        [-4.6107e-02],\n",
       "        [ 1.7426e-01],\n",
       "        [-4.2026e-02],\n",
       "        [ 2.7977e-02],\n",
       "        [ 3.3828e-02],\n",
       "        [-9.2744e-02],\n",
       "        [ 1.1177e-01],\n",
       "        [-7.6453e-02],\n",
       "        [-5.0951e-02],\n",
       "        [ 1.7682e-01],\n",
       "        [-2.4675e-01],\n",
       "        [-7.7275e-02],\n",
       "        [ 1.2922e-01],\n",
       "        [-1.4243e-01],\n",
       "        [ 2.1320e-01],\n",
       "        [ 3.3798e-02],\n",
       "        [-8.2140e-02],\n",
       "        [-2.1781e-01],\n",
       "        [ 2.5011e-01],\n",
       "        [-1.6775e-01],\n",
       "        [ 2.0667e-01],\n",
       "        [-1.3915e-01],\n",
       "        [ 5.6199e-02],\n",
       "        [-1.5765e-01],\n",
       "        [ 1.6363e-01],\n",
       "        [ 2.5766e-01],\n",
       "        [-2.1628e-01],\n",
       "        [ 4.2167e-01],\n",
       "        [-2.9698e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"../model/model\")\n",
    "print(\"Model saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

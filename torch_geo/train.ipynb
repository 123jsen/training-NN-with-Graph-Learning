{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This notebook trains the TrainerGCN using the provided dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\GitHub-Projects\\training-NN-with-Graph-Learning\n"
     ]
    }
   ],
   "source": [
    "cd .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Downloaded libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "# Local files\n",
    "from datasets.graph_data import NNDataset\n",
    "from models.graph import TrainerGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging Settings\n",
    "torch.set_printoptions(threshold=12500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAINING_SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epoch = 8\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = None\n",
    "# transform = T.Compose([T.ToUndirected()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded, 1120 training samples and 280 testing samples\n"
     ]
    }
   ],
   "source": [
    "nndataset = NNDataset(root=\"./\", transform=transform)\n",
    "\n",
    "size = len(nndataset)\n",
    "train_num = int(size * TRAINING_SPLIT)\n",
    "test_num = size - train_num\n",
    "\n",
    "print(\n",
    "    f\"Dataset loaded, {train_num} training samples and {test_num} testing samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(design=[3], edge_index=[2, 40], x=[13, 503], edge_weight=[40, 1], y_node=[13, 1], y_edge=[40, 1], input_mask=[13, 1], num_nodes=13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of the Data\n",
    "\n",
    "data = nndataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=nndataset[:train_num], batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(\n",
    "    dataset=nndataset[train_num:], batch_size=test_num, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 140\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of batches:\", int(train_num / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrainerGCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainerGCN(\n",
       "  (conv1): GATConv(503, 128, heads=1)\n",
       "  (conv2): GATConv(128, 128, heads=1)\n",
       "  (dense_1B): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dense_1W): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        data.to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        out_w, out_b = model(data)\n",
    "        loss = 0\n",
    "        loss += loss_fn(out_b, data.y_node)\n",
    "        loss += loss_fn(out_w, data.y_edge)\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print status every n batches\n",
    "        if i % 35 == 0:\n",
    "            loss, current = loss.item(), i * batch_size\n",
    "            print(\n",
    "                f\"Training Loss: {loss:>7f}  [{current:>5d}/{train_num:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = iter(dataloader).next().to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        out_w, out_b = model(data)\n",
    "        loss = loss_fn(out_b, data.y_node) + loss_fn(out_w, data.y_edge)\n",
    "\n",
    "        loss = loss.item()\n",
    "        print(f\"Validation Loss: {loss:>7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 8:\n",
      "Training Loss: 0.296614  [    0/ 1120]\n",
      "Training Loss: 0.216534  [  280/ 1120]\n",
      "Training Loss: 0.188380  [  560/ 1120]\n",
      "Training Loss: 0.198405  [  840/ 1120]\n",
      "Validation Loss: 0.299190\n",
      "Epoch 2 / 8:\n",
      "Training Loss: 0.145682  [    0/ 1120]\n",
      "Training Loss: 0.153649  [  280/ 1120]\n",
      "Training Loss: 0.166315  [  560/ 1120]\n",
      "Training Loss: 0.164751  [  840/ 1120]\n",
      "Validation Loss: 0.189213\n",
      "Epoch 3 / 8:\n",
      "Training Loss: 0.192565  [    0/ 1120]\n",
      "Training Loss: 0.137330  [  280/ 1120]\n",
      "Training Loss: 0.129178  [  560/ 1120]\n",
      "Training Loss: 0.130158  [  840/ 1120]\n",
      "Validation Loss: 0.117470\n",
      "Epoch 4 / 8:\n",
      "Training Loss: 0.125586  [    0/ 1120]\n",
      "Training Loss: 0.115377  [  280/ 1120]\n",
      "Training Loss: 0.183392  [  560/ 1120]\n",
      "Training Loss: 0.133694  [  840/ 1120]\n",
      "Validation Loss: 0.144282\n",
      "Epoch 5 / 8:\n",
      "Training Loss: 0.117384  [    0/ 1120]\n",
      "Training Loss: 0.116269  [  280/ 1120]\n",
      "Training Loss: 0.136261  [  560/ 1120]\n",
      "Training Loss: 0.135745  [  840/ 1120]\n",
      "Validation Loss: 0.134949\n",
      "Epoch 6 / 8:\n",
      "Training Loss: 0.118069  [    0/ 1120]\n",
      "Training Loss: 0.144607  [  280/ 1120]\n",
      "Training Loss: 0.158629  [  560/ 1120]\n",
      "Training Loss: 0.123477  [  840/ 1120]\n",
      "Validation Loss: 0.149810\n",
      "Epoch 7 / 8:\n",
      "Training Loss: 0.114012  [    0/ 1120]\n",
      "Training Loss: 0.129634  [  280/ 1120]\n",
      "Training Loss: 0.108322  [  560/ 1120]\n",
      "Training Loss: 0.108133  [  840/ 1120]\n",
      "Validation Loss: 0.147789\n",
      "Epoch 8 / 8:\n",
      "Training Loss: 0.098947  [    0/ 1120]\n",
      "Training Loss: 0.120645  [  280/ 1120]\n",
      "Training Loss: 0.118641  [  560/ 1120]\n",
      "Training Loss: 0.137806  [  840/ 1120]\n",
      "Validation Loss: 0.144268\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "for epoch in range(num_epoch):\n",
    "    print(f\"Epoch {epoch + 1} / {num_epoch}:\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Using One Instance of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(design=[3], edge_index=[2, 40], x=[13, 503], edge_weight=[40, 1], y_node=[13, 1], y_edge=[40, 1], input_mask=[13, 1], num_nodes=13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = nndataset[0]\n",
    "data = data.to(device)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 8, 2]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_w, out_b = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0274],\n",
       "        [ 0.0265],\n",
       "        [ 0.0219],\n",
       "        [ 0.0205],\n",
       "        [ 0.0271],\n",
       "        [ 0.0245],\n",
       "        [ 0.0194],\n",
       "        [ 0.0283],\n",
       "        [-0.0364],\n",
       "        [-0.0373],\n",
       "        [-0.0418],\n",
       "        [-0.0432],\n",
       "        [-0.0367],\n",
       "        [-0.0393],\n",
       "        [-0.0443],\n",
       "        [-0.0354],\n",
       "        [-0.0287],\n",
       "        [-0.0295],\n",
       "        [-0.0341],\n",
       "        [-0.0354],\n",
       "        [-0.0289],\n",
       "        [-0.0316],\n",
       "        [-0.0365],\n",
       "        [-0.0277],\n",
       "        [-0.0060],\n",
       "        [ 0.0004],\n",
       "        [-0.0069],\n",
       "        [-0.0005],\n",
       "        [-0.0115],\n",
       "        [-0.0051],\n",
       "        [-0.0128],\n",
       "        [-0.0064],\n",
       "        [-0.0063],\n",
       "        [ 0.0001],\n",
       "        [-0.0089],\n",
       "        [-0.0025],\n",
       "        [-0.0139],\n",
       "        [-0.0075],\n",
       "        [-0.0051],\n",
       "        [ 0.0013]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2277],\n",
       "        [-0.5283],\n",
       "        [ 0.0862],\n",
       "        [-0.3806],\n",
       "        [ 1.1312],\n",
       "        [-0.5555],\n",
       "        [-0.4393],\n",
       "        [-0.4372],\n",
       "        [ 1.0530],\n",
       "        [ 0.4600],\n",
       "        [-0.4602],\n",
       "        [-0.3724],\n",
       "        [-0.6324],\n",
       "        [-0.3388],\n",
       "        [-0.4321],\n",
       "        [-0.0846],\n",
       "        [ 0.3264],\n",
       "        [-0.4622],\n",
       "        [ 0.4405],\n",
       "        [ 0.3594],\n",
       "        [ 0.1728],\n",
       "        [-1.1223],\n",
       "        [ 0.6651],\n",
       "        [ 0.2089],\n",
       "        [-0.6755],\n",
       "        [ 0.5243],\n",
       "        [-0.4433],\n",
       "        [ 0.1207],\n",
       "        [ 0.5847],\n",
       "        [-0.5651],\n",
       "        [-0.0793],\n",
       "        [-0.0928],\n",
       "        [ 0.5919],\n",
       "        [-0.6201],\n",
       "        [-0.1842],\n",
       "        [ 0.6789],\n",
       "        [ 0.5201],\n",
       "        [-0.5449],\n",
       "        [ 0.1860],\n",
       "        [ 0.1699]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../trained_model/gnnmodel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\GitHub-Projects\\training-NN-with-Graph-Learning\\torch_geo\\train.ipynb Cell 29'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GitHub-Projects/training-NN-with-Graph-Learning/torch_geo/train.ipynb#ch0000028?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49msave(model\u001b[39m.\u001b[39;49mstate_dict(), \u001b[39m\"\u001b[39;49m\u001b[39m../trained_model/gnnmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub-Projects/training-NN-with-Graph-Learning/torch_geo/train.ipynb#ch0000028?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mModel saved\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\serialization.py:377\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[39m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \n\u001b[0;32m    343\u001b[0m \u001b[39mSaves an object to a disk file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[39m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    375\u001b[0m _check_dill_version(pickle_module)\n\u001b[1;32m--> 377\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    378\u001b[0m     \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    379\u001b[0m         \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 231\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    232\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 212\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../trained_model/gnnmodel'"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"./trained_model/gnnmodel\")\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Simple_NN\n",
    "from dataset_traindata import ClassificationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SOURCE = \"../raw/dataset_0/\"\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 150\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading from csv\n",
    "dataset = ClassificationData('../raw/dataset_0/')\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple_NN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 5 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.774198  [    0/  500]\n",
      "loss: 0.695837  [  160/  500]\n",
      "loss: 0.679394  [  320/  500]\n",
      "loss: 0.681822  [  300/  500]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.666636  [    0/  500]\n",
      "loss: 0.623423  [  160/  500]\n",
      "loss: 0.612933  [  320/  500]\n",
      "loss: 0.611979  [  300/  500]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.590459  [    0/  500]\n",
      "loss: 0.550266  [  160/  500]\n",
      "loss: 0.550991  [  320/  500]\n",
      "loss: 0.549148  [  300/  500]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.528797  [    0/  500]\n",
      "loss: 0.474737  [  160/  500]\n",
      "loss: 0.491730  [  320/  500]\n",
      "loss: 0.488498  [  300/  500]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.480889  [    0/  500]\n",
      "loss: 0.407049  [  160/  500]\n",
      "loss: 0.436074  [  320/  500]\n",
      "loss: 0.428700  [  300/  500]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.440318  [    0/  500]\n",
      "loss: 0.353085  [  160/  500]\n",
      "loss: 0.387334  [  320/  500]\n",
      "loss: 0.369295  [  300/  500]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.407037  [    0/  500]\n",
      "loss: 0.310064  [  160/  500]\n",
      "loss: 0.345007  [  320/  500]\n",
      "loss: 0.313789  [  300/  500]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.379166  [    0/  500]\n",
      "loss: 0.281887  [  160/  500]\n",
      "loss: 0.312602  [  320/  500]\n",
      "loss: 0.268954  [  300/  500]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.361552  [    0/  500]\n",
      "loss: 0.260015  [  160/  500]\n",
      "loss: 0.288278  [  320/  500]\n",
      "loss: 0.236858  [  300/  500]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.351612  [    0/  500]\n",
      "loss: 0.247601  [  160/  500]\n",
      "loss: 0.270874  [  320/  500]\n",
      "loss: 0.214569  [  300/  500]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.344211  [    0/  500]\n",
      "loss: 0.240880  [  160/  500]\n",
      "loss: 0.257711  [  320/  500]\n",
      "loss: 0.198367  [  300/  500]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.339048  [    0/  500]\n",
      "loss: 0.235784  [  160/  500]\n",
      "loss: 0.247314  [  320/  500]\n",
      "loss: 0.186800  [  300/  500]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.333856  [    0/  500]\n",
      "loss: 0.232680  [  160/  500]\n",
      "loss: 0.239111  [  320/  500]\n",
      "loss: 0.178402  [  300/  500]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.328651  [    0/  500]\n",
      "loss: 0.230889  [  160/  500]\n",
      "loss: 0.232497  [  320/  500]\n",
      "loss: 0.171836  [  300/  500]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.323699  [    0/  500]\n",
      "loss: 0.229072  [  160/  500]\n",
      "loss: 0.227076  [  320/  500]\n",
      "loss: 0.166518  [  300/  500]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.319211  [    0/  500]\n",
      "loss: 0.227309  [  160/  500]\n",
      "loss: 0.222513  [  320/  500]\n",
      "loss: 0.162539  [  300/  500]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.315104  [    0/  500]\n",
      "loss: 0.225698  [  160/  500]\n",
      "loss: 0.218828  [  320/  500]\n",
      "loss: 0.159188  [  300/  500]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.311992  [    0/  500]\n",
      "loss: 0.223761  [  160/  500]\n",
      "loss: 0.215888  [  320/  500]\n",
      "loss: 0.156506  [  300/  500]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.308068  [    0/  500]\n",
      "loss: 0.222205  [  160/  500]\n",
      "loss: 0.213251  [  320/  500]\n",
      "loss: 0.154090  [  300/  500]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.305014  [    0/  500]\n",
      "loss: 0.220097  [  160/  500]\n",
      "loss: 0.210972  [  320/  500]\n",
      "loss: 0.151788  [  300/  500]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.301795  [    0/  500]\n",
      "loss: 0.218020  [  160/  500]\n",
      "loss: 0.208960  [  320/  500]\n",
      "loss: 0.149954  [  300/  500]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.298932  [    0/  500]\n",
      "loss: 0.216468  [  160/  500]\n",
      "loss: 0.206941  [  320/  500]\n",
      "loss: 0.148306  [  300/  500]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.296339  [    0/  500]\n",
      "loss: 0.214528  [  160/  500]\n",
      "loss: 0.204929  [  320/  500]\n",
      "loss: 0.146628  [  300/  500]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.293881  [    0/  500]\n",
      "loss: 0.212589  [  160/  500]\n",
      "loss: 0.203012  [  320/  500]\n",
      "loss: 0.145028  [  300/  500]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.291613  [    0/  500]\n",
      "loss: 0.210545  [  160/  500]\n",
      "loss: 0.201097  [  320/  500]\n",
      "loss: 0.143240  [  300/  500]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.289538  [    0/  500]\n",
      "loss: 0.209062  [  160/  500]\n",
      "loss: 0.199688  [  320/  500]\n",
      "loss: 0.141934  [  300/  500]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.287365  [    0/  500]\n",
      "loss: 0.207947  [  160/  500]\n",
      "loss: 0.198340  [  320/  500]\n",
      "loss: 0.140648  [  300/  500]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.285408  [    0/  500]\n",
      "loss: 0.206505  [  160/  500]\n",
      "loss: 0.196881  [  320/  500]\n",
      "loss: 0.139339  [  300/  500]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.283655  [    0/  500]\n",
      "loss: 0.205209  [  160/  500]\n",
      "loss: 0.195822  [  320/  500]\n",
      "loss: 0.138388  [  300/  500]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.281677  [    0/  500]\n",
      "loss: 0.203677  [  160/  500]\n",
      "loss: 0.194571  [  320/  500]\n",
      "loss: 0.137252  [  300/  500]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.279899  [    0/  500]\n",
      "loss: 0.202311  [  160/  500]\n",
      "loss: 0.193548  [  320/  500]\n",
      "loss: 0.136352  [  300/  500]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.278034  [    0/  500]\n",
      "loss: 0.201350  [  160/  500]\n",
      "loss: 0.192715  [  320/  500]\n",
      "loss: 0.135530  [  300/  500]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.276572  [    0/  500]\n",
      "loss: 0.199954  [  160/  500]\n",
      "loss: 0.191660  [  320/  500]\n",
      "loss: 0.134751  [  300/  500]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.275049  [    0/  500]\n",
      "loss: 0.199260  [  160/  500]\n",
      "loss: 0.190713  [  320/  500]\n",
      "loss: 0.133589  [  300/  500]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.274038  [    0/  500]\n",
      "loss: 0.197598  [  160/  500]\n",
      "loss: 0.189778  [  320/  500]\n",
      "loss: 0.133212  [  300/  500]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.271689  [    0/  500]\n",
      "loss: 0.197421  [  160/  500]\n",
      "loss: 0.189129  [  320/  500]\n",
      "loss: 0.132426  [  300/  500]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.270722  [    0/  500]\n",
      "loss: 0.195858  [  160/  500]\n",
      "loss: 0.188158  [  320/  500]\n",
      "loss: 0.131850  [  300/  500]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.269188  [    0/  500]\n",
      "loss: 0.195391  [  160/  500]\n",
      "loss: 0.187599  [  320/  500]\n",
      "loss: 0.131387  [  300/  500]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.267456  [    0/  500]\n",
      "loss: 0.194410  [  160/  500]\n",
      "loss: 0.186851  [  320/  500]\n",
      "loss: 0.130598  [  300/  500]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.266214  [    0/  500]\n",
      "loss: 0.193597  [  160/  500]\n",
      "loss: 0.186138  [  320/  500]\n",
      "loss: 0.130064  [  300/  500]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.265021  [    0/  500]\n",
      "loss: 0.192773  [  160/  500]\n",
      "loss: 0.185382  [  320/  500]\n",
      "loss: 0.129656  [  300/  500]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.263304  [    0/  500]\n",
      "loss: 0.192125  [  160/  500]\n",
      "loss: 0.184909  [  320/  500]\n",
      "loss: 0.128985  [  300/  500]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.261846  [    0/  500]\n",
      "loss: 0.190924  [  160/  500]\n",
      "loss: 0.184127  [  320/  500]\n",
      "loss: 0.128059  [  300/  500]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.261043  [    0/  500]\n",
      "loss: 0.190015  [  160/  500]\n",
      "loss: 0.183488  [  320/  500]\n",
      "loss: 0.127551  [  300/  500]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.259070  [    0/  500]\n",
      "loss: 0.189700  [  160/  500]\n",
      "loss: 0.183066  [  320/  500]\n",
      "loss: 0.126800  [  300/  500]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.257979  [    0/  500]\n",
      "loss: 0.188841  [  160/  500]\n",
      "loss: 0.182298  [  320/  500]\n",
      "loss: 0.126139  [  300/  500]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.256931  [    0/  500]\n",
      "loss: 0.188397  [  160/  500]\n",
      "loss: 0.182073  [  320/  500]\n",
      "loss: 0.125673  [  300/  500]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.255844  [    0/  500]\n",
      "loss: 0.187643  [  160/  500]\n",
      "loss: 0.181531  [  320/  500]\n",
      "loss: 0.125215  [  300/  500]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.254735  [    0/  500]\n",
      "loss: 0.187113  [  160/  500]\n",
      "loss: 0.180984  [  320/  500]\n",
      "loss: 0.124649  [  300/  500]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.253707  [    0/  500]\n",
      "loss: 0.186453  [  160/  500]\n",
      "loss: 0.180476  [  320/  500]\n",
      "loss: 0.124143  [  300/  500]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.252557  [    0/  500]\n",
      "loss: 0.185963  [  160/  500]\n",
      "loss: 0.179887  [  320/  500]\n",
      "loss: 0.123509  [  300/  500]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.252045  [    0/  500]\n",
      "loss: 0.185498  [  160/  500]\n",
      "loss: 0.179647  [  320/  500]\n",
      "loss: 0.123146  [  300/  500]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.251072  [    0/  500]\n",
      "loss: 0.184625  [  160/  500]\n",
      "loss: 0.179292  [  320/  500]\n",
      "loss: 0.122758  [  300/  500]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.249993  [    0/  500]\n",
      "loss: 0.184563  [  160/  500]\n",
      "loss: 0.178907  [  320/  500]\n",
      "loss: 0.122251  [  300/  500]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.249061  [    0/  500]\n",
      "loss: 0.183985  [  160/  500]\n",
      "loss: 0.178304  [  320/  500]\n",
      "loss: 0.121219  [  300/  500]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.249271  [    0/  500]\n",
      "loss: 0.182807  [  160/  500]\n",
      "loss: 0.178191  [  320/  500]\n",
      "loss: 0.121272  [  300/  500]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.247391  [    0/  500]\n",
      "loss: 0.182770  [  160/  500]\n",
      "loss: 0.177679  [  320/  500]\n",
      "loss: 0.120558  [  300/  500]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.247522  [    0/  500]\n",
      "loss: 0.182084  [  160/  500]\n",
      "loss: 0.177536  [  320/  500]\n",
      "loss: 0.120322  [  300/  500]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.246896  [    0/  500]\n",
      "loss: 0.181476  [  160/  500]\n",
      "loss: 0.177019  [  320/  500]\n",
      "loss: 0.119957  [  300/  500]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.245705  [    0/  500]\n",
      "loss: 0.181502  [  160/  500]\n",
      "loss: 0.176535  [  320/  500]\n",
      "loss: 0.119328  [  300/  500]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.245898  [    0/  500]\n",
      "loss: 0.180328  [  160/  500]\n",
      "loss: 0.176498  [  320/  500]\n",
      "loss: 0.119444  [  300/  500]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.244628  [    0/  500]\n",
      "loss: 0.180074  [  160/  500]\n",
      "loss: 0.176095  [  320/  500]\n",
      "loss: 0.118983  [  300/  500]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.244204  [    0/  500]\n",
      "loss: 0.179924  [  160/  500]\n",
      "loss: 0.175733  [  320/  500]\n",
      "loss: 0.118649  [  300/  500]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.243739  [    0/  500]\n",
      "loss: 0.179142  [  160/  500]\n",
      "loss: 0.175219  [  320/  500]\n",
      "loss: 0.118123  [  300/  500]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.243863  [    0/  500]\n",
      "loss: 0.178454  [  160/  500]\n",
      "loss: 0.174982  [  320/  500]\n",
      "loss: 0.118403  [  300/  500]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.242021  [    0/  500]\n",
      "loss: 0.178625  [  160/  500]\n",
      "loss: 0.174476  [  320/  500]\n",
      "loss: 0.117402  [  300/  500]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.243430  [    0/  500]\n",
      "loss: 0.177129  [  160/  500]\n",
      "loss: 0.174242  [  320/  500]\n",
      "loss: 0.117837  [  300/  500]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.240925  [    0/  500]\n",
      "loss: 0.178437  [  160/  500]\n",
      "loss: 0.173303  [  320/  500]\n",
      "loss: 0.116829  [  300/  500]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.242403  [    0/  500]\n",
      "loss: 0.176411  [  160/  500]\n",
      "loss: 0.173029  [  320/  500]\n",
      "loss: 0.116882  [  300/  500]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.240770  [    0/  500]\n",
      "loss: 0.177507  [  160/  500]\n",
      "loss: 0.172920  [  320/  500]\n",
      "loss: 0.116295  [  300/  500]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.241024  [    0/  500]\n",
      "loss: 0.175973  [  160/  500]\n",
      "loss: 0.172430  [  320/  500]\n",
      "loss: 0.116216  [  300/  500]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.239709  [    0/  500]\n",
      "loss: 0.176618  [  160/  500]\n",
      "loss: 0.172216  [  320/  500]\n",
      "loss: 0.115657  [  300/  500]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.240500  [    0/  500]\n",
      "loss: 0.175554  [  160/  500]\n",
      "loss: 0.171726  [  320/  500]\n",
      "loss: 0.115560  [  300/  500]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.239333  [    0/  500]\n",
      "loss: 0.176053  [  160/  500]\n",
      "loss: 0.171457  [  320/  500]\n",
      "loss: 0.115196  [  300/  500]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.238999  [    0/  500]\n",
      "loss: 0.175003  [  160/  500]\n",
      "loss: 0.171140  [  320/  500]\n",
      "loss: 0.114944  [  300/  500]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.237815  [    0/  500]\n",
      "loss: 0.175039  [  160/  500]\n",
      "loss: 0.170715  [  320/  500]\n",
      "loss: 0.114306  [  300/  500]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.238249  [    0/  500]\n",
      "loss: 0.173876  [  160/  500]\n",
      "loss: 0.170673  [  320/  500]\n",
      "loss: 0.114324  [  300/  500]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.236438  [    0/  500]\n",
      "loss: 0.175076  [  160/  500]\n",
      "loss: 0.169946  [  320/  500]\n",
      "loss: 0.113059  [  300/  500]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.237844  [    0/  500]\n",
      "loss: 0.173399  [  160/  500]\n",
      "loss: 0.170075  [  320/  500]\n",
      "loss: 0.113613  [  300/  500]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.235301  [    0/  500]\n",
      "loss: 0.174100  [  160/  500]\n",
      "loss: 0.169533  [  320/  500]\n",
      "loss: 0.112848  [  300/  500]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.237086  [    0/  500]\n",
      "loss: 0.172844  [  160/  500]\n",
      "loss: 0.169260  [  320/  500]\n",
      "loss: 0.113115  [  300/  500]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.234517  [    0/  500]\n",
      "loss: 0.173900  [  160/  500]\n",
      "loss: 0.168784  [  320/  500]\n",
      "loss: 0.112436  [  300/  500]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.235446  [    0/  500]\n",
      "loss: 0.172162  [  160/  500]\n",
      "loss: 0.168448  [  320/  500]\n",
      "loss: 0.112192  [  300/  500]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.234413  [    0/  500]\n",
      "loss: 0.172511  [  160/  500]\n",
      "loss: 0.168330  [  320/  500]\n",
      "loss: 0.111938  [  300/  500]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.234044  [    0/  500]\n",
      "loss: 0.171834  [  160/  500]\n",
      "loss: 0.167875  [  320/  500]\n",
      "loss: 0.111577  [  300/  500]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.233765  [    0/  500]\n",
      "loss: 0.171676  [  160/  500]\n",
      "loss: 0.167926  [  320/  500]\n",
      "loss: 0.111456  [  300/  500]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.232750  [    0/  500]\n",
      "loss: 0.171183  [  160/  500]\n",
      "loss: 0.167404  [  320/  500]\n",
      "loss: 0.110876  [  300/  500]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.232796  [    0/  500]\n",
      "loss: 0.170640  [  160/  500]\n",
      "loss: 0.167648  [  320/  500]\n",
      "loss: 0.110797  [  300/  500]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.232166  [    0/  500]\n",
      "loss: 0.170641  [  160/  500]\n",
      "loss: 0.166922  [  320/  500]\n",
      "loss: 0.110575  [  300/  500]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.231622  [    0/  500]\n",
      "loss: 0.170358  [  160/  500]\n",
      "loss: 0.166938  [  320/  500]\n",
      "loss: 0.109964  [  300/  500]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.230936  [    0/  500]\n",
      "loss: 0.169258  [  160/  500]\n",
      "loss: 0.167212  [  320/  500]\n",
      "loss: 0.109832  [  300/  500]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.229708  [    0/  500]\n",
      "loss: 0.169115  [  160/  500]\n",
      "loss: 0.166638  [  320/  500]\n",
      "loss: 0.109332  [  300/  500]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.229652  [    0/  500]\n",
      "loss: 0.168547  [  160/  500]\n",
      "loss: 0.166643  [  320/  500]\n",
      "loss: 0.109127  [  300/  500]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.228408  [    0/  500]\n",
      "loss: 0.168084  [  160/  500]\n",
      "loss: 0.166330  [  320/  500]\n",
      "loss: 0.108413  [  300/  500]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.227955  [    0/  500]\n",
      "loss: 0.167085  [  160/  500]\n",
      "loss: 0.166316  [  320/  500]\n",
      "loss: 0.108438  [  300/  500]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.227035  [    0/  500]\n",
      "loss: 0.167043  [  160/  500]\n",
      "loss: 0.166367  [  320/  500]\n",
      "loss: 0.108256  [  300/  500]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.226402  [    0/  500]\n",
      "loss: 0.166568  [  160/  500]\n",
      "loss: 0.165972  [  320/  500]\n",
      "loss: 0.107590  [  300/  500]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.226581  [    0/  500]\n",
      "loss: 0.165485  [  160/  500]\n",
      "loss: 0.165855  [  320/  500]\n",
      "loss: 0.107563  [  300/  500]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.225110  [    0/  500]\n",
      "loss: 0.166501  [  160/  500]\n",
      "loss: 0.165750  [  320/  500]\n",
      "loss: 0.107028  [  300/  500]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.224927  [    0/  500]\n",
      "loss: 0.164454  [  160/  500]\n",
      "loss: 0.165439  [  320/  500]\n",
      "loss: 0.106756  [  300/  500]\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.224104  [    0/  500]\n",
      "loss: 0.164918  [  160/  500]\n",
      "loss: 0.165621  [  320/  500]\n",
      "loss: 0.106794  [  300/  500]\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.223361  [    0/  500]\n",
      "loss: 0.164037  [  160/  500]\n",
      "loss: 0.165014  [  320/  500]\n",
      "loss: 0.106817  [  300/  500]\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.222777  [    0/  500]\n",
      "loss: 0.164372  [  160/  500]\n",
      "loss: 0.164570  [  320/  500]\n",
      "loss: 0.106257  [  300/  500]\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.223244  [    0/  500]\n",
      "loss: 0.163322  [  160/  500]\n",
      "loss: 0.164451  [  320/  500]\n",
      "loss: 0.106452  [  300/  500]\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.220799  [    0/  500]\n",
      "loss: 0.163586  [  160/  500]\n",
      "loss: 0.164088  [  320/  500]\n",
      "loss: 0.105335  [  300/  500]\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.222188  [    0/  500]\n",
      "loss: 0.162356  [  160/  500]\n",
      "loss: 0.164314  [  320/  500]\n",
      "loss: 0.105957  [  300/  500]\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.220394  [    0/  500]\n",
      "loss: 0.162148  [  160/  500]\n",
      "loss: 0.163622  [  320/  500]\n",
      "loss: 0.105123  [  300/  500]\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.220599  [    0/  500]\n",
      "loss: 0.162403  [  160/  500]\n",
      "loss: 0.163798  [  320/  500]\n",
      "loss: 0.105206  [  300/  500]\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.219199  [    0/  500]\n",
      "loss: 0.161632  [  160/  500]\n",
      "loss: 0.163577  [  320/  500]\n",
      "loss: 0.104415  [  300/  500]\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.218906  [    0/  500]\n",
      "loss: 0.161415  [  160/  500]\n",
      "loss: 0.163293  [  320/  500]\n",
      "loss: 0.104248  [  300/  500]\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.218853  [    0/  500]\n",
      "loss: 0.160486  [  160/  500]\n",
      "loss: 0.163335  [  320/  500]\n",
      "loss: 0.104313  [  300/  500]\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.217345  [    0/  500]\n",
      "loss: 0.161880  [  160/  500]\n",
      "loss: 0.162907  [  320/  500]\n",
      "loss: 0.103585  [  300/  500]\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.217947  [    0/  500]\n",
      "loss: 0.159261  [  160/  500]\n",
      "loss: 0.162730  [  320/  500]\n",
      "loss: 0.103436  [  300/  500]\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.216319  [    0/  500]\n",
      "loss: 0.160107  [  160/  500]\n",
      "loss: 0.162836  [  320/  500]\n",
      "loss: 0.102870  [  300/  500]\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.216364  [    0/  500]\n",
      "loss: 0.159272  [  160/  500]\n",
      "loss: 0.162631  [  320/  500]\n",
      "loss: 0.102604  [  300/  500]\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.215688  [    0/  500]\n",
      "loss: 0.159099  [  160/  500]\n",
      "loss: 0.162421  [  320/  500]\n",
      "loss: 0.102462  [  300/  500]\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.214764  [    0/  500]\n",
      "loss: 0.159115  [  160/  500]\n",
      "loss: 0.161972  [  320/  500]\n",
      "loss: 0.101878  [  300/  500]\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.214386  [    0/  500]\n",
      "loss: 0.158428  [  160/  500]\n",
      "loss: 0.161620  [  320/  500]\n",
      "loss: 0.101408  [  300/  500]\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.213582  [    0/  500]\n",
      "loss: 0.158066  [  160/  500]\n",
      "loss: 0.161809  [  320/  500]\n",
      "loss: 0.100921  [  300/  500]\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.213352  [    0/  500]\n",
      "loss: 0.157168  [  160/  500]\n",
      "loss: 0.161786  [  320/  500]\n",
      "loss: 0.100510  [  300/  500]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.212655  [    0/  500]\n",
      "loss: 0.157185  [  160/  500]\n",
      "loss: 0.161775  [  320/  500]\n",
      "loss: 0.100071  [  300/  500]\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.212704  [    0/  500]\n",
      "loss: 0.156910  [  160/  500]\n",
      "loss: 0.161622  [  320/  500]\n",
      "loss: 0.100124  [  300/  500]\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.211586  [    0/  500]\n",
      "loss: 0.155939  [  160/  500]\n",
      "loss: 0.161392  [  320/  500]\n",
      "loss: 0.099676  [  300/  500]\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.210376  [    0/  500]\n",
      "loss: 0.156082  [  160/  500]\n",
      "loss: 0.161015  [  320/  500]\n",
      "loss: 0.099006  [  300/  500]\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.210667  [    0/  500]\n",
      "loss: 0.155964  [  160/  500]\n",
      "loss: 0.160976  [  320/  500]\n",
      "loss: 0.098866  [  300/  500]\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.210840  [    0/  500]\n",
      "loss: 0.155528  [  160/  500]\n",
      "loss: 0.161023  [  320/  500]\n",
      "loss: 0.099221  [  300/  500]\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.209730  [    0/  500]\n",
      "loss: 0.155028  [  160/  500]\n",
      "loss: 0.160680  [  320/  500]\n",
      "loss: 0.098646  [  300/  500]\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.208710  [    0/  500]\n",
      "loss: 0.154757  [  160/  500]\n",
      "loss: 0.160529  [  320/  500]\n",
      "loss: 0.098185  [  300/  500]\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.208666  [    0/  500]\n",
      "loss: 0.154916  [  160/  500]\n",
      "loss: 0.159965  [  320/  500]\n",
      "loss: 0.097909  [  300/  500]\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.209062  [    0/  500]\n",
      "loss: 0.153467  [  160/  500]\n",
      "loss: 0.160229  [  320/  500]\n",
      "loss: 0.097756  [  300/  500]\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.207996  [    0/  500]\n",
      "loss: 0.154799  [  160/  500]\n",
      "loss: 0.160264  [  320/  500]\n",
      "loss: 0.097875  [  300/  500]\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.207264  [    0/  500]\n",
      "loss: 0.152618  [  160/  500]\n",
      "loss: 0.159880  [  320/  500]\n",
      "loss: 0.097402  [  300/  500]\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.207117  [    0/  500]\n",
      "loss: 0.153103  [  160/  500]\n",
      "loss: 0.159634  [  320/  500]\n",
      "loss: 0.096903  [  300/  500]\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.206464  [    0/  500]\n",
      "loss: 0.152824  [  160/  500]\n",
      "loss: 0.159579  [  320/  500]\n",
      "loss: 0.096738  [  300/  500]\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.206184  [    0/  500]\n",
      "loss: 0.152213  [  160/  500]\n",
      "loss: 0.159431  [  320/  500]\n",
      "loss: 0.096889  [  300/  500]\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.205461  [    0/  500]\n",
      "loss: 0.151891  [  160/  500]\n",
      "loss: 0.159006  [  320/  500]\n",
      "loss: 0.096111  [  300/  500]\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.205697  [    0/  500]\n",
      "loss: 0.151647  [  160/  500]\n",
      "loss: 0.159545  [  320/  500]\n",
      "loss: 0.096368  [  300/  500]\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.204300  [    0/  500]\n",
      "loss: 0.152393  [  160/  500]\n",
      "loss: 0.158835  [  320/  500]\n",
      "loss: 0.095401  [  300/  500]\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.205275  [    0/  500]\n",
      "loss: 0.150839  [  160/  500]\n",
      "loss: 0.158389  [  320/  500]\n",
      "loss: 0.095188  [  300/  500]\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.204499  [    0/  500]\n",
      "loss: 0.151406  [  160/  500]\n",
      "loss: 0.158663  [  320/  500]\n",
      "loss: 0.095032  [  300/  500]\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.203739  [    0/  500]\n",
      "loss: 0.150707  [  160/  500]\n",
      "loss: 0.158258  [  320/  500]\n",
      "loss: 0.094673  [  300/  500]\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.204014  [    0/  500]\n",
      "loss: 0.150156  [  160/  500]\n",
      "loss: 0.157941  [  320/  500]\n",
      "loss: 0.094377  [  300/  500]\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.203266  [    0/  500]\n",
      "loss: 0.150280  [  160/  500]\n",
      "loss: 0.157990  [  320/  500]\n",
      "loss: 0.094831  [  300/  500]\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.202401  [    0/  500]\n",
      "loss: 0.149739  [  160/  500]\n",
      "loss: 0.157695  [  320/  500]\n",
      "loss: 0.094350  [  300/  500]\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.201694  [    0/  500]\n",
      "loss: 0.149131  [  160/  500]\n",
      "loss: 0.157349  [  320/  500]\n",
      "loss: 0.093701  [  300/  500]\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.202156  [    0/  500]\n",
      "loss: 0.149126  [  160/  500]\n",
      "loss: 0.157385  [  320/  500]\n",
      "loss: 0.094096  [  300/  500]\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.201123  [    0/  500]\n",
      "loss: 0.148612  [  160/  500]\n",
      "loss: 0.156989  [  320/  500]\n",
      "loss: 0.093966  [  300/  500]\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.200734  [    0/  500]\n",
      "loss: 0.148709  [  160/  500]\n",
      "loss: 0.156771  [  320/  500]\n",
      "loss: 0.093460  [  300/  500]\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.201334  [    0/  500]\n",
      "loss: 0.147509  [  160/  500]\n",
      "loss: 0.156618  [  320/  500]\n",
      "loss: 0.093770  [  300/  500]\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.199426  [    0/  500]\n",
      "loss: 0.148185  [  160/  500]\n",
      "loss: 0.156330  [  320/  500]\n",
      "loss: 0.093144  [  300/  500]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(num_epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, output = data\n",
    "input = input.to(device)\n",
    "output = output.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0295, 0.9705], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = model(input)\n",
    "out = nn.Softmax(dim=-1)(out)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
